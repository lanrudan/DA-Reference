---
title: "ABTest"
---

## 概览

  本章介绍AB测试。**AB测试**（也称为随机对照试验 - RCT, Randomized Controlled Trial）是一种用于因果推断的实验设计方法。其核心在于通过**随机分配**将受试单元（用户、会话、页面访问等）分配到不同的处理组（通常是A：对照组/Baseline，B：新方案组），在控制其他变量（通过随机化）的前提下，比较不同处理对特定目标指标的影响，从而决定哪个更优。

  本章参考了\@knuth84

## 理论基础

### 因果推断的基石：潜在结果框架与随机化

1.  **潜在结果框架（Neyman-Rubin Causal Model）：**

    -   **定义**：对于每个实验单元$i$（用户、会话等），定义两个潜在结果：

        -   $Y_i(1)$：单元$i$接受处理$B$（干预）时的结果

        -   $Y_i(0)$：单元$i$接受处理$A$（对照）时的结果

    -   **个体处理效应：**$\text{ITE} = \tau_i = Y_i(1) - Y_i(0)$

    -   **根本问题**：对于任何单元$i$，我们只能观察到$Y_i(1)$或$Y_i(0)$，永远无法同时观测两者，观察到的结果$Y_i^{obs} = Z_i * Y_i(1) + (1 - Z_i) * Y_i(0)$，其中$Z_i$是指示变量，$Z_i=1$ 表示分配到$B$组，$Z_i=0$ 表示分配到$A$组)。

    -   **目标**：估计**平均处理效应**$\text{ATE} = \tau = E[\tau_i] = E[Y_i(1)-Y_i(0)]=E[Y(1)]-E[Y(0)]$

2.  **随机化**

-   **关键假设（Ignorability/Unconfoundedness）**：通过**完全随机分配**，我们确保处理分配$Z_i$独立于潜在结果，即$Y_i(1),Y_i(0) \perp Z_i$，这意味着$E[Y_i(1) | Z_i=1] = E[Y_i(1) | Z_i=0] = E[Y_i(1)]$（同理于$Y_i(0)$）。

-   **无偏估计量：**基于观测数据，ATE 的一个简单无偏估计量是**组间均值差**$$\hat{τ}_{DiM} = \hat{E}[Y^{obs} | Z=1] - \hat{E}[Y^{obs} | Z=0] = \bar{Y}_B - \bar{Y}_A$$

    -   **证明无偏性**： $$E[\hat{τ}_{DiM}] = E[\bar{Y}_B - \bar{Y}_A] = E[\bar{Y}_B] - E[\bar{Y}_A] = E[Y(1) | Z=1] - E[Y(0) | Z=0]$$（根据观测数据定义）

        由于随机化（$Y_i(1),Y_i(0) \perp Z_i$），有$E[Y(1) | Z=1] = E[Y(1)]$且$E[Y(0) | Z=0] = E[Y(0)]$ 因此$E[\hat{τ}_{DiM}] = E[Y(1)] - E[Y(0)] = ATE$

-   **协变量平衡 (Covariate Balance):** 随机化也确保所有观测到的$X$ 和未观测到的 $U$ 混杂因素（Confounders）在组间的分布是相同的（渐近意义上）： $F(X | Z=1) = F(X | Z=0)$和$F(U | Z=1) = F(U | Z=0)$

这是实现$Y(1),Y(0) \perp Z$的关键保障。AA测试检查的就是观测到的 X是否平衡。

### 假说检验

1.  **核心框架**

-   原假设$H_0$：$ATE = 0$或等价的$\mu_A = \mu_B$（总体均值相等）或$p_A = p_B$（总体比例相等）。

-   备择假设$H_1$：$ATE \neq 0$（双尾）或$ATE>0$或$ATE<0$（单尾）。

-   检验统计量$T$：构造一个统计量，其分布在$H_0$成立时已知（或渐进已知）。

-   $P-value$：$p=P\left(|T| \geq \left|t_{obs}\right| \middle| H_0\right)$，即$H_0$成立时，观察到当前统计量$t_{obs}$甚至于更极端值的概率。

-   决策：若$p<\alpha$，$\alpha$为我们预设的显著性水平，则拒绝$H_0$。

2.  **连续性指标：双样本**$t$**检验**

  例如平均订单金额、会话时长。

-   假设：

    -   独立性Independent Samples

    -   正态性Normality：每组数据近似正态分布（或样本量足够大，依赖CLT）

    -   方差齐性Homoscedasticity：$\sigma_A^2 = \sigma_B^2 = \sigma^2$

-   检验统计量：

$$t = \frac{(\bar{Y}_B - \bar{Y}_A) - 0}{s_p \sqrt{\frac{1}{n_A} + \frac{1}{n_B}}}$$ 其中$s_p² = \frac{(n_A - 1)s_A² + (n_B - 1)s_B²}{n_A + n_B - 2}$是合并方差估计量 (Pooled Variance Estimator)，$s_A^2$，$s_B^2$是样本方差，$n_A$，$n_B$是样本量。

-   分布：在$H_0$和假设成立的条件下，$t \sim t_{df}$，自由度$df = n_A+n_B-2$

-   方差不齐 (Welch's t-test):若方差不齐，使用调整后的统计量和自由度， $$t = \frac{\bar{Y}_B - \bar{Y}_A}{\sqrt{\frac{s_A²}{n_A} + \frac{s_B²}{n_B}}}$$，自由度为$df ≈ \frac{(\frac{s_A²}{n_A} + \frac{s_B²}{n_B})²}{\frac{(s_A²/n_A)²}{n_A - 1} + \frac{(s_B²/n_B)²}{n_B - 1}}$

3.  **比例型指标：双样本比例检验（**$Z$**检验）**

  例如点击率、转化率。

-   假设：

    -   独立性

    -   大样本：$(n_A p_A > 5, n_A (1-p_A) > 5, n_B p_B > 5, n_B (1-p_B) > 5)$，确保二项分布近似正态。

-   检验统计量（基于合并比例）： $$Z = \frac{\hat{p}_B - \hat{p}_A}{\sqrt{\hat{p}(1-\hat{p}) (\frac{1}{n_A} + \frac{1}{n_B})}}$$ 其中$\hat{p} = \frac{X_A + X_B}{n_A + n_B}$，$X_A$，$X_B$是成功的次数，是$H_0(p_A =p_B = p)$下$p$的合并估计量。

-   分布：在$H_0$和假设成立的条件下，$Z\sim N(0, 1)$（渐近）。

-   基于独立方差（更常用且推荐）：

$$Z = \frac{\hat{p}_B - \hat{p}_A}{\sqrt{\hat{p}(1-\hat{p}) (\frac{1}{n_A} + \frac{1}{n_B})}}$$，这个版本不依赖与$H_0$下$p_A=p_B$的假设，在构建置信区间时更加自然，检验功效稍低但是更稳健。渐近分布同样是$N(0, 1)$。

4.  **计数型指标**   例如人均点击次数。常假设服从泊松分布，使用基于泊松回归或负二项回归的检验（处理过离散问题）。

5.  **置信区间（CI）**

-   概念：基于样本数据构造一个区间$(L, U)$，使得我们要估计的参数$\theta$（我们这里是$ATE$）落在这个区间的概率是$1-\alpha$，即$P(L\leq \theta \leq U) = 1-\alpha$。频率学派的解释是，重复多次试验，每次构造一个CI，那么大约$1-\alpha$的CI会包含真实的$\theta$。以下均以双尾检验为例。

-   连续性指标（差异）： $$(\bar{Y}_B - \bar{Y}_A) \pm t_{df, 1-\alpha/2} \times SE(\bar{Y}_B - \bar{Y}_A)$$ 其中 $SE(\bar{Y}\_B - \bar{Y}\_A) = \sqrt{\frac{s_A²}{n_A} + \frac{s_B²}{n_B}}$（Welch)）或$s_p \sqrt{\frac{1}{n_A} + \frac{1}{n_B}}$（Pooled）。

-   比例型指标（差异）：$$(\hat{p}_B - \hat{p}_A) \pm Z_{1-\alpha/2} \times \sqrt{\frac{\hat{p}_A(1-\hat{p}_A)}{n_A} + \frac{\hat{p}_B(1-\hat{p}_B)}{n_B}}$$

-   解读：如果95%CI不包含0，则双尾验证在\$\alpha \$显著性水平下显著。CI宽度反映了估计的精确度。

### 统计功效与样本量计算

1.  定义与公式

-   I类错误（$\alpha$）：$H_0$为真时，错误地拒绝$H_0$。也就是说宣称有差异实际没有。

-   II类错误（$\beta$）：$H_1$为真时，没有拒绝$H_0$。也就是说实际上有差异但是没有检测到。

-   功效（Power）$1-\beta$：$P(\text{Reject } H₀ | H₁ \text{ is true})$。即当真实效应$\delta = |ATE|$（或$|\mu_B -\mu_A|$，$|p_B - p_A|$）存在且等于最小期望检测效应（MDE）时，正确拒绝$H_0$的概率。**换句话说，就是当处理B确实比A好（**$H_1$为真）时，正确拒绝$H_0$的概率$1-\beta$。

-   影响功效的关键因素（以双样本$t$检验为例）：

    -   效应量（$\delta$）:期望检测到的最小有意义的差异$\delta = \frac{|\mu_B - \mu_A|}{\sigma}$，这是标准化效应量，Cohen'sd。$\delta$越大，功效越高，$\delta$越小，检测所需要的样本量越大。

    -   样本量（$n = n_A= n_B$）:$n$越大，功效越高，功效$\propto \sqrt{n}$

    -   显著性水平（$\alpha$）：犯I类错误（假阳性）的概率。$\alpha$越大，即允许更多假阳性，功效越高。$\alpha$越小，所需要样本量越大。

    -   方差（$\sigma^2$）：$\sigma^2$越大，功效越低。指标本身的变异性越大，检测相同效应量所需的样本量越大（对于连续型指标）。

    -   基准比率（p_A）：对于比例指标，基准转化率影响方差（p(1-p)），在p=0.5时最大。

-   样本量计算公式（双样本$t$检验，双尾，等样本量）：

$$n \approx \frac{2 (Z_{1-\alpha/2} + Z_{1-\beta})^2 \sigma^2}{\delta^2}$$

其中$Z_{1-\alpha/2},Z_{1-\beta}$是标准正态分布的分位数，$\delta$是未标准化的效应量($|\mu_B-\mu_A|$)。这个公式推导基于$H_0$下的统计量$\sim N(0, 1)$，$H_1$下的统计量$\sim N(\frac{\delta}{\sigma \sqrt{2/n}}, 1)$，令两个分布的拒绝域边界相交即可解出$n$。

-   比例型指标（双样本比例检验，双尾，等样本量）：

$$n \approx \frac{ (Z_{1-\alpha/2} \sqrt{2\bar{p}(1-\bar{p})} + Z_{1-\beta} \sqrt{p_A(1-p_A) + p_B(1-p_B)} )² }{\delta²}$$ 其中$\delta = |p_B-p_A|,\bar{p} = \frac{p_A+p_B}{2}$，推导类似，考虑$H_0$下方差基于$\bar{p}$，$H1$下方差基于真实的$p_A$和$p_B$。

### 方差估计的挑战（用户级随机化）

-   问题核心：在用户级随机化的AB测试中，分析单元（如页面浏览PV，点击Click）与随机化单元（用户User）不一致。同一个用户的不同事件/行为不独立。

-   后果：传统的方差估计公式（如$\frac{s^2}{n}$）会严重低估真实方差，导致：

    -   CI过窄

    -   $p-value$过小，I类错误率（假阳性率）膨胀

-   数学解释：

    -   假设有$m$个用户$i = 1...m$，用户$i$贡献$n_i$个观测值（如$PV$），总观测值$N = \sum_i n_i$

    -   核心指标$Y$在用户$i$上的平均为$\bar{Y}_i$

    -   组件差异估计量$\hat{\tau} = \bar{Y}_B - \bar{Y}_A$

    -   其真实方差为：$Var(\hat{τ}) = Var(\frac{1}{m_B} \sum_{i \in B} \bar{Y}_i - \frac{1}{m_A} \sum_{j \in A} \bar{Y}_j)$，由于用户间是独立的，$Var(\hat{τ}) = \frac{Var(\bar{Y}_i | B)}{m_B} + \frac{Var(\bar{Y}_j | A)}{m_A}$

    -   而传统方差估计（假设观测独立）为：$\widehat{Var}_{naive}(\hat{τ}) \approx \frac{s_B²}{N_B} + \frac{s_A²}{N_A}$，其中$N_B = \sum_{i \in B} n_i$（B组总观测数），$s_B^2$是基于所有B组观测值计算的方差

    -   $\widehat{Var}_{naive}$会系统性小于$Var(\hat{\tau})$，因为忽略了用户的内相关性。低估的程度取决于用户内相关性的强度和用户行为次数$n_i$的变异度。

-   解决方案：

    -   $Delta$ $Method$：推倒$\hat{\tau}$方差的理论表达式并进行估计。适用于特定指标类型（如人均指标）。

    -   聚类标准误（Cluster-Robust Standard Errors - CRSE）：将方差估计建立在随机化单元（用户）的层面。

        -   将每一个用户视为一个“聚类”

        -   计算每个用户$i$对$\hat{\tau}$的“得分”（Influence Function）或残差贡献$e_i$

        -   聚类标准误为： $\widehat{Var}_{CR}(\hat{τ}) = \frac{m}{m-1} \frac{m}{m_A m_B} \sum_{i=1}^m (\tilde{e}_i - \bar{\tilde{e}})^2$，其中$\tilde{e}_i$是用户$i$的聚合残差贡献（具体形式取决于模型）。这是最常用且稳健的方法。

    -   Booststrap（聚类Booststrap）：对用户进行重抽样（而不是对观测值），保持用户的所有数据完整。每次重抽样后计算$\hat{\tau}$，用多次（B次）重抽样得到的$\hat{\tau}^{(b)}$的方差来估计$\hat{\tau}$。计算量大但是灵活。

### 多重检验问题（Multiple Testing Problem）

-   问题核心：同时进行$K$次独立的假设检验，每个检验的显著性水平都为$\alpha$。那么至少出现一次假阳性（I类错误）的概率（族系错误率FWER,Family-Wise Error Rate）是$$FWER = P(\text{至少一个错误拒绝} | \text{所有 } H₀ \text{ 为真}) = 1 - (1 - α)^K ≈ Kα \quad (\text{当 } α \text{ 很小时})$$，即使$\alpha = 0.05$，当$K$为10时，FWER约为0.4，假阳性率非常高。

-   ABTest中的来源：

    -   同时测试多个核心指标（$K>1$）

    -   同时测试多个变体（A/B/C/D...测试，$K>1$个比较）

    -   数据窥探（Peeking）：在实验运行期间多次查看结果并进行检验。每次查看都是一次独立的检验机会（$K$很大）。

-   控制方法（待补充）

### 进阶统计视角（待补充）

  AB测试的统计学原理深植于**因果推断**的潜在结果框架，**随机化**是其无偏估计的基石。**假设检验 (t/Z检验)**提供决策依据，**置信区间**量化不确定性。**功效分析**确保实验可靠性，**样本量计算**是实验设计的核心。实践中必须警惕**方差低估 (用户级相关性)** 和**多重检验膨胀**，采用聚类标准误或校正方法。贝叶斯方法和序贯检验提供了替代视角和效率提升。理解异质性效应能挖掘更深价值。掌握这些原理，是设计和解读可靠AB测试的关键。

## AB测试的流程与步骤

  ABtest其实就是控制变量法。为了评估测试和验证模型/项目的效果，在app/pc端设计出多个版本，在同一时间维度下，分别用组成相同/相似的群组去随机访问这些版本，记录下群组的用户体验数据和业务数据，最后评估不同方案的效果决定是否上线。

### 1.**明确目标与假设**

-   定义清晰的业务目标（如提升注册转化率、增加平均订单价值）。

-   提出具体的、可证伪的统计假设（$H_0$和$H_1$）。

-   确定期望检测的最小有意义效应量MDE

### 2.**确定目标指标与护栏指标**

-   **核心指标（Primary Metrics）：**直接反映实验目标的1-2个关键指标（如转化率、收入）
    -   例如：修改购买页面的主色调能够帮助用户购买率提升3%

    -   那么用户购买率就是我们关注的

    -   还需要关注一些新策略是否会对其他重要指标产生负面影响
-   **护栏指标（Guardrail Metrics）：**监控实验潜在负面影响的指标（如页面加载时间、关键功能使用率、崩溃率）。确保优化核心指标不以牺牲其他重要方面为代价。
    -   Organization Guardrail Metrics：新功能可能好但是加载慢；该付款界面UI对用户的下单单价不能有影响

    -   Trustworthy-related metrics：比如检查randomization，要用T-test或者卡方检验在查看A/B组的其他特征一致性
-   **探索性指标（Exploratory Metrics）**：帮助理解用户行为变化，发现意外结果的辅助指标。

### 3.**实验设计**

-   单元选择（Unit of Diversion/randomization Unit）：决定随机化的最小单元（用户ID，设备ID，会话ID，页面访问）。选择时需要考虑指标计算（用户级指标需用户级分流）、用户多次体验（保持体验一致性）、样本独立性（避免干扰）。用户级分流最常见。

-   分流比例（Traffic Allocation）：分配多少样本去A/B组。通常是50:50，这样统计效率最高。但也会根据风险、流量大小调整（如90:10，新方案流量少）。需要确保样本量足够。

-   样本量计算（Sample Size Estimation）：基于$\alpha, \beta, MDE$，基准值（$p_A$或$\sigma_A$）计算每组所需要的最小样本量/实验时长。这一点至关重要！样本不足会导致功效低（II类错误风险高），样本过大浪费资源和时间。

-   分层与区组（Sractification&Blocking）：在随机化钱按重要特征（如国家、设备类型、用户新老）分层或区组，确保这些特征在组间均衡分布，提高统计精度（尤其当特征与指标强相关时）。

-   触发与曝光（Triggering&Exposure）：明确那些用户会被纳入实验（所有的访问者？特定路径访问者？）。以及何时记录他们被“曝光”于实验条件、确保分析对象是真正“看到了”实验变化的用户，称为“曝光后分析”。

  下面将具体举例进行介绍。

-   **WHO**

  AB实验实验需要控制变量，确保两组中只有一个不同的变量，其余变量一致。

-   必须满足的条件：

    -   特征相同或相似的用户群组

    -   同一时间维度

-   操作方法：

    -   利用用户唯一标识的尾号或者其他标识进行分类，如奇偶分为两组

    -   用一个hash函数将用户的唯一标识进行取模，分桶。可以将用户均匀地分到若干桶中，如分到100/1000个桶中，这样的好处就是可以进一步将用户打散，提高分组的效果。

-   当然，如果有多个分组并行的情况的话，要考虑独占域和分享域问题。独占域指不同域之间的用户相互独立，交集为空。对于共享域，我们要进行分层。但是在分层中，下一层要将上一层的用户打散，确保下一层用户的随机性。

-   实验对象：

    -   如果是双边市场的话，可以从用户、平台、生产者三方进行实验

        -   双边市场：指平台同时服务两类或多类相互依存的客户。例如，淘宝连接了买家和卖家，滴滴连接了乘客和司机，内容平台连接了用户和创作者。

        -   信息流实验：指的是围绕“信息”在用户和生产者之间流动的过程所进行的实验。推荐系统是其中的核心组成部分。

        -   用户（C端实验）

            -   是最常见的AB实验场景，直接面向用户

            -   产品策略：例如新功能上线，用户界面UI改版

            -   运营策略：比如推送通知的文案、活动页面设计

            -   客户端改版：例如APP的新版本、页面布局的调整

            -   核心目标：提升用户体验，提高留存度和活跃度

        -   cp/内容生产者（B端实验）

            -   面向内容生产者或者商家的产品和策略

            -   例如：内容池优化（让创作者更方便地上传内容）、创作者激励（新的分成机制）、黑产打击（识别和处理恶意内容）。

            -   旨在提升B端的生产效率、积极性，维护平台生态健康

        -   推荐实验（平台侧）

            -   面对：链接用户和CP的关键桥梁---推荐算法

            -   例子：自动训参（Auto-tuning，自动调整推荐算法的参数）、召回优化（提高找到用户可能喜欢的内容的效率）、排序优化（更好的对召回内容进行排序）、多目标优化（同时考虑点击率、停留市场、GMV等多个指标）、体验优化（减少广告干扰）、人群策略（针对特定人群提供定制化推荐）。推荐算法的效果直接影响着用户和CP两段的满意度。

    -   推荐实验常用试验方法：（未展开，有机会可以展开）

        -   ABTest

        -   上线实验

        -   MAB实验

        -   在线寻参

-   人群圈选方式（行为圈选、标签圈选、属性圈选）

    -   多层方案

        -   分流：用户分流是指按照地域、性别、年龄等等将用户均匀地分成几个组，1个用户只能出现在1个组中。

            -   适合互斥实验：实验在同一层拆分流量，且无论怎么拆分，不同组的流量是不会重叠的

            -   例如“安卓用户”，“只看北京用户”。很多情况中不同城市的用户的的情况会有很大差别

            -   问题：实际情况中，往往会上线多个实验。例如可能同时上线样式形态、广告位置策略、预估模型的实验。如果只按照分流模式来说，在每组实验放量10%的情况下，整体的流量只能同时开展10个实验。效率很低。为了解决这个问题，提出了用户分层、流量复用的方法。

        -   分层：同一份流量可以分布在多个实验层，也就是说**同一批用户可以出现在不同的实验层**，前提是**各个实验层之间无业务关联**，保证**这一批用户都均匀地分布到所有的实验层中**，达到用户正交的效果就可以，从而让实验流量复用。

            -   根据业务方人为定义一些分层--如：UI层、推荐算法层

            -   每一层对用户随机分组：流量经过每一层时都会被打散重新分配，下一层的每一组的流量都随机来源于上一层各组的流量

            -   实现同一个用户出现在不同层的不同组中，流量重复利用

        -   分流分层模型：在此模型中增加组、层，并且可以相互嵌套。要求与实际的业务相匹配，拆分过多的结构可能会把简单的业务复杂化，拆分过少的结构又可能不满足实际业务。

  上图就是分流分层模型的一个简单的图示。我们有：域1+域2=100%流量，B1层=B2层=B3层=域2流量，(B1-1)+(B1-2)+(B1-3)=B1层流量

-   规则：

    -   域1和域2拆分流量，即域1域2互斥

    -   流量流过域2中的B1层、B2层、B3层时，B1层、B2层、B3层的流量都与域2的流量相等，此时B1层、B2层、B3层的流量是正交的

    -   流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2,B1-3，此时B1-1，B1-2,B1-3又是互斥的

-   使用场景：

    -   例1：B1层、B2层、B3层可能分别为：UI层、搜索结果层、广告结果层，这基层基本上没有业务关联，即使共用相同的流量（流量正交）也不会对实际的业务造成结果。

    -   但是如果不同层之间所进行的实验相互关联，如B1层是修改的一个页面的按钮文字颜色，B2层时修改的按钮的颜色，当按钮文字颜色和文字颜色一样时，该按钮以及不可用了。因此建议同一类型的实验在同一层内进行，并且需要考虑到不同实验互相的依赖。

    -   例2：域1的此种分流意义在于：如果我们希望其他任何实验都不能对我们的实验造成干扰，保证最后实验的可信度。

-   B端实验

    -   内容池：

        -   业务策略：低质过滤、热点运营、内容引入、内容使用天数

        -   模型更新：tag更新、清晰度调整、封面图调整、评分体系更新

    -   内容创作者：

        -   业务策略：账号过滤、账号提权、账号引入、分润策略

        -   模型更新：评级模型更新、黑产打击模型更新

-   **what**——选物料

  明确改动点——话术模版/H5/图片素材，保证是单一因素

-   **where**——选渠道

  短信/外呼/邮件/站内私信

-   **when**——选时机

  立即出发/定时触达/例行触达/事件触发

  注意：实验时长要与产品的“数据特征周期”一致

  例如：直播类app产品，用户在周一到周五的活跃度较低，在周末活跃度高，以一个自然周为周期，不断循环。那么该产品的实验的时长应设置为一周。

-   **How Large**——决定样本量

    -   在前面有介绍过具体公式，这里简化为$N  \approx \frac{16 \times \sigma^2}{\delta^2}$

        -   样本标准差$\sigma$衡量了整体样本数据的波动性

            -   观测指标为绝对值类指标时：$\sigma^2 = \frac{\sum_i^n(x_i-\bar{x})^2}{n-1}$

            -   观测指标为比率类指标时：$\sigma^2 = p_A(1-p_A)+p_B(1-p_B)$，$p_A,p_B$为观测数据，比如希望点击率从20%提升到25%，那么$p_A=0.2,p_B=0.25,\delta = 5%$

        -   组间预期差值$\delta$代表预期实验组和对照组两组数据的差

        -   这里我们取$\alpha = 0.05,\beta=0.2$，这里体现了AB实验的保守理念：低的$\alpha$，尽量避免在$H_0$为真的时候拒绝它，；高的$\beta$，可以适当的接受假的$H_0$，也就是说改进实际游泳但是不采取；总结下来就是宁肯砍掉多个号的产品，也不应该让任何不好的产品上线。

            ::: callout-note
            为什么我们需要计算最小样本量？

            理论上样本量肯定是越大越好。实际上，样本量是越小越好，因为

            -   流量有限：小公司就这么点流量，还要精打细算做各种测试，开发各种产品。在保证样本分组不重叠的基础上，产品开发速度会大大降低。

            -   试错成本大：如果拿50%的用户做实验，一周以后发现总收入下降了20%，这样一周时间的实验给公司造成了10%的损失，这样损失未免有点大。

            所以也可以应用一个流量大小Trick——RAMP-UP PLAN or 灰度测试：初始阶段,先分配较少的流量（如1%）进入实验，初始实验如果一切正常, 进一步加大流量，初始实验如果出现异常, 随时可以终止实验
            :::

    -   理论基础——CLT

        -   当样本量足够大的时候，样本均值$\bar{x}$的分布近似服从正态分布。

        -   当$H_0$为真的时候 ，实验组的样本均值$\bar{x}$服从均值为$\mu_t = \mu_c$，方差为$\frac{\sigma^2}{n}$的正态分布。

        标准化后的$Z$统计量：$Z=\frac{\bar{x}-(\mu_c-\mu_t)}{\sqrt{2\sigma^2/n}}$

        第二类错误是指在H0为假的时候，我们错误地接受了H0，也就是说Z统计量落在了接受域内。

$$\beta = P(|\frac{\bar{x}}{\sqrt{2\sigma^2/n}}| \le Z_{\alpha/2}) = P(-Z_{\alpha/2} \le \frac{\bar{x} - (\mu_c - \mu_t)}{\sqrt{2\sigma^2/n}} \le Z_{\alpha/2})$$

  由于中间部分服从标准正态分布，所以这个概率可以用正态分布的累计函数$\Phi$来表示：

$$\beta= \Phi(Z_{\alpha/2} - \frac{\mu_c - \mu_t}{\sqrt{2\sigma^2/n}}) - \Phi(-Z_{\alpha/2} - \frac{\mu_c - \mu_t}{\sqrt{2\sigma^2/n}})$$   不失一般性，我们假设$\mu_c>\mu_t$是一个比较大的整数，所以其中第二项$\Phi(-Z_{\alpha/2} - \frac{\mu_c - \mu_t}{\sqrt{2\sigma^2/n}})$的值会非常小，接近与0，因此可以忽略。与此同时，我们知道$\beta = \Phi(-Z_{\beta})$，最终可以得到$$n \approx \frac{2(Z_{\alpha/2} + Z_\beta)^2 \sigma^2}{(\mu_c - \mu_t)^2}$$。其中$\delta = |\mu_t-\mu_c|$是我们希望检测到的最小可检测效应MDE。$\sigma^2$是指标的方差，通常需要预估或者根据历史数据计算。

  以上公式是计算出单个实验组所需的样本量，若有多个实验组，乘以实验组的个数就可以得到最终的样本量；样本量也可以是一段时间里累计的样本量，比如需要10000个样本，每天1000个，累计10天也是可以的。

-   举例：

    -   对于绝对值指标：

        -   某商品详情页平均停留时长的标准差是20s，优化了商品详情页面后，预估至少有5s的提升，AB测试每个组需要的最少样本量：$\sigma = 20,\delta=5$，每个组所需要的最少的样本量就是16\*20**2/5**2=256

    -   比率类指标：

        -   某商品详情页点击率20%，优化后预期点击率提升到25%，每个组需要的最少样本量：16*(0.2*0.8+0.25\*0.75)/(0.25-0.2)\*\*2

-   在线计算工具：[Evans awesome AB Tools](https://www.evanmiller.org/ab-testing/)

-   代码（基于$delta$ $method$）:$\sqrt{n}(g(Y_n) - g(\theta)) \xrightarrow{d} N(0, \sigma^2 g'(\theta)^2)$

```{r, echo=FALSE, warning=FALSE}
library(reticulate)
use_condaenv("mineenv", required = TRUE)
```

```{python}
import numpy as np
import math
from sklearn.linear_model import MultiTaskLasso, Lasso
import pandas as pd
import scipy.stats
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

```

1.  用卡方检验检验分流的均匀性

-   x 和 y：通常代表实验组和对照组的用户总数（或流量总数）。代码中的 31188, 31188 表示两组的流量是相等的。

-   x_target 和 y_target：通常代表实验组和对照组中某个特定事件的发生次数，例如转化、点击等。代码中的 3461, 3423 是两组的转化次数。

-   如果p-value非常小（比如小于0.05），说明两组的流量分布存在显著差异，可能分流有问题，实验结果不可信。

```{python}
from scipy.stats import chi2_contingency
def chi_test(x,y,x_target,y_target):
    kf_data = np.array([[x,x_target], [y,y_target]])
    kf = chi2_contingency(kf_data)
    print('chi-sq=%.4f, p-value=%.4f, df=%i expected_frep=%s'%kf)

chi_test(31188,31188,3461,3423)
```

2.  德尔塔方法计算方差

-   计算两个随机变量之比的方差。在ABTest中，CTR = 点击数/曝光数，CVR = 转化数/点击数，这两个指标本质上都是两个随机变量的商。

-   问题背景：传统的二项分布方差公式适用于伯努利试验（例如每个用户点击或者不点击）。但是对于比率指标，分母本身也是一个随机变量。这时使用简单的二项分布公式来估算方差就不正确了。

-   推导：假设我们需要计算$R = Y/X$的方差。通过一阶泰勒展开近似，得到$Var(\hat{R}) = Var\left(\frac{\bar{Y}}{\bar{X}}\right) \approx \left(\frac{\partial g}{\partial x}\right)^2 Var(\bar{X}) + \left(\frac{\partial g}{\partial y}\right)^2 Var(\bar{Y}) + 2\left(\frac{\partial g}{\partial x}\right)\left(\frac{\partial g}{\partial y}\right)Cov(\bar{X}, \bar{Y})$，其中$g(x,y) = \frac{y}{x},  \frac{\partial g}{\partial x} = -\frac{y}{x^2}, \frac{\partial g}{\partial y} = \frac{1}{x}$，代入得到$\Rightarrow Var(\hat{R}) \approx \frac{E[Y]^2}{E[X]^4} Var(\bar{X}) + \frac{1}{E[X]^2} Var(\bar{Y}) - \frac{2E[Y]}{E[X]^3} Cov(\bar{X}, \bar{Y})$

```{python}
def var_dtm(y_mean, x_mean, var_y, var_x, xy_mean):
    #计算协方差
    def cova(x_mean,y_mean,xy_mean):
        return xy_mean-x_mean*y_mean
    covar = cova(x_mean,y_mean,xy_mean)
    
    #商的variance
    var_ratio = var_y/x_mean**2 + var_x*y_mean**2/x_mean**4 - 2*covar*y_mean/x_mean**3
    return var_ratio
  
  
#发布器头图的 曝光数 > 发布数 为例
var = var_dtm(y_mean = 0.035214194, x_mean = 2.794877088302219
                ,var_y = 0.073726526, var_x = 185.240175
                    , xy_mean = 0.410843231521)


#实际的方差 有可能比二项分布折算方差会大很多
print('二项方差：',round(0.012599/(1-0.012599),4))
print('实际方差：',round(var,4))

```

3.  估算样本量

```{python}
'''
mean:对照组指标的均值（如基准转化率）
var：指标的方差，代码在调用时会分别使用“二项分布方差”和“德尔塔方法方差”。
lift_rate：预期的最小可检测效应\delta
'''
def sample_size(mean = 0.01259955,var = 0.0122,lift_rate = 0.025,alpha = 0.05,beta = 0.2):
    import math
    
    lift = lift_rate * mean
    num = var*(scipy.stats.norm.ppf(1-alpha)+scipy.stats.norm.ppf(1-beta))**2/(lift**2)
    return math.ceil(num)

print('采用二项方差的样本量估计：', sample_size(var = 0.0128))
print('采用deltaMethod的样本量估计：',sample_size())
```

### 4.实施与随机化，数据收集与监控

-   开发并部署实验变体（B）

    -   创建变体：对网站原有版本的元素进行所需要更改。可能是更改颜色，交换页面上元素是顺序，隐藏导航元素或完全自定义的内容。

-   构建可靠的随机化引擎，确保分配是真正的随机且不可预测的。常用方法：用户ID哈希取模、伪随机数生成器（需要确保seed独立）。

-   记录分配日志（用户ID，时间戳、分配组、实验ID）（埋点）

    -   这里要注意辛普森悖论！要严格执行之前设计的分流分层方案让样本均匀随机。

-   收集核心指标、护栏指标、探索性指标的数据（埋点采集数据）

-   实时/准实时监控：

    -   样本量积累情况
    
        -   比如实验组和对照组的分流的流量是否均匀
    
    -   核心指标的点估计和置信区间变化
    
    -   护栏指标是否有异常波动（设置警报阈值）
    
    -   检查AA测试是否通过
    
    -   观察对于用户的行为埋点是否埋的正确
    
### 5.数据分析

-   数据准备：清洗数据，处理异常值，确认分析窗口（如实验开始后稳定期的数据）。

-   AA测试/平衡检验：在分析AB结果之前，先检查实验组（A）和对照组（A）在**已知不受实验影响**的指标上（如实验前历史数据、用户属性、分流前行为）是否存在显著差异。若显著，表明随机化可能失败或者数据有问题，需要排查。

-   效应估计：计算核心指标的组间差异$\bar{y}_B-\bar{y}_A$或者$\hat{p}_B-\hat{p}_A$

-   统计显著性差异：使用合适的检验方法（t检验、Z检验、回归）计算P值

-   CI构建：计算效应量的CI

-   多重检验校正：如果同时考虑多个核心指标或者同一个指标的多个变体（A/B/n测试），需要进行校正，以控制整体错误发现率（FDR）或族系错误率（FWER）。容易忽视但是很重要！

-   效应量解读：结合实际业务解读统计学差异是否显著。一个统计学上显著但是效应量微小的结果可能没有实际意义。

### 6.决策
