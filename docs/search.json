[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data",
    "section": "",
    "text": "前言\n数据学习过程中的笔记，希望能够对大家也有所帮助。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  简介",
    "section": "",
    "text": "学习数据分析过程的笔记。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>简介</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "01metrics.html",
    "href": "01metrics.html",
    "title": "3  行业指标梳理",
    "section": "",
    "text": "3.1 概览\n本章是行业的指标梳理。主要分为电商(E-commerce)、短视频(Short Video)、直播/直播电商(Live)、社交媒体(Social Media)、风控。\n指标体系的目的是为了了解业务全貌，快速业务定位问题、以及明确解决方案。\n首先，是要确定我们的战略目标，以及与之对应的北极星指标。第二步，看为了达到这个北极星指标所需要达到业务链路是哪些（例如AARRR模型：Acquistion：获取用户；Activation：提高活跃度；Retention：提高留存率；Revenue：获取收入；Refer：自传播）。第三步，围绕业务流程设计维度和指标。第四步，最后用趋势、对比、细分、分布的方式去aggregate各种指标；趋势即通过折线图看到数据指标的走势和波动，让涨跌幅度可视化；对比包括同比和环比，同比是指今年某月/某季度和去年某月/某季度相比，环比可以是环比上周/上月；对比数据除了能反映出业务发展情况之外，还可以帮助排除季节性或周期性的影响因素；细分是指某个指标的具体来源组成，比如在看商品详情页的曝光量的时候，不仅要看总曝光量，还要分析每个曝光是从哪个页面进来的（首页、活动页、搜索框、商品分类页、排行榜页等等）；分布是指某个指标的来源占比，比如上面这个商品的曝光量来源。第五步，形成分析SOP和数据看板。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>行业指标梳理</span>"
    ]
  },
  {
    "objectID": "01metrics.html#电子商务ecommerce",
    "href": "01metrics.html#电子商务ecommerce",
    "title": "3  行业指标梳理",
    "section": "3.2 电子商务(Ecommerce)",
    "text": "3.2 电子商务(Ecommerce)\n  并非所有的指标都有价值，我们需要确定需要跟踪的关键绩效指标（KPI）来提高绩效。在线销售是可靠增长是来自于分析业务不同部分随时间变化的绩效。随着时sss间的推移，跟踪正确是指标将提高在线销售。行业有着共同的KPI，但是每个企业都有独特的KPI需要定期跟踪和分析，以改进其产品、服务或与客户的互动。All KPIs are metrics;not all metrics are KPIs.\n\n3.2.1 Mindmap\n\n\n\n\n\nmindmap\n  root((E-commerce))\n    总体运营 Overall operating\n    平台流量 Web traffic （场）\n    客户价值 Customer value （人）\n    商品价值 Goods value （货）\n    销售转化 Sales conversion\n    市场营销 Marketing\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((总体运营 Overall operating))\n    维度\n      顾客/用户 Customer\n      商家/店铺 Merchant\n        店铺类型 Store type(个人Individual/企业Enterprise/钻级Level等)\n    指标\n      PV（Page View）/UV（Unique Vistor）\n      商品交易总额GMV(Gross Merchandise Volume) \n      订单数 Number of orders\n      客单价 （销售额/交易次数）/ATV(Average Transaction Value)\n      销售额 Revenue\n      成本 COGS\n      毛利率 Gross margin\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((平台流量 Web traffic（场）))\n      维度\n        时段 Time period\n        PC/Mobile\n        不同板块 Section\n        页面位置 Page\n        主页Home\n        商品详情页Product detail\n        购物车页Shopping cart\n      指标\n        PV/UV\n        DAU、WAU、MAU（Daily/Weekly/Monthly Active Users）\n        用户粘性User stickiness(DAU/MAU)\n        页面访问时长\n        页面访问数量\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((客户价值 Customer value（人）))\n      维度\n        新老客 New/old\n        年龄层 Age group\n        性别 Gender\n        城市 City\n        是否会员 Membership\n        注册来源 Register source\n        注册时长 Register time\n        行业 Industry\n      指标\n        RFM分类\n        AARRR分类\n\n\n\n\n\n\n  其中RFM分类如下表所示，可以基于此给用户打分。\n\n\n\n\n\n\n\n\n\n用户分类\n最近一次消费时间间隔 (R)\n消费频率 (F)\n消费金额 (M)\n\n\n\n\n1. 重要价值用户\n高\n高\n高\n\n\n2. 重要发展用户\n高\n低\n高\n\n\n3. 重要保持用户\n低\n高\n高\n\n\n4. 重要挽留用户\n低\n低\n高\n\n\n5. 一般价值用户\n高\n高\n低\n\n\n6. 一般发展用户\n高\n低\n低\n\n\n7. 一般保持用户\n低\n高\n低\n\n\n8. 一般挽留用户\n低\n低\n低\n\n\n\n  AARRR分类如下图所示：\n\n\n\n\n\ngraph LR\n    subgraph AARRR[\"AARRR模型\"]\n        direction LR\n        A[Acquisition 获取]\n        B[Activation 激活]\n        C[Retention 存留]\n        D[Revenue 收益]\n        E[Referral 推荐]\n    end\n\n    %% 子内容展开\n    A --&gt; A1[\"用户从不同渠道来到产品\"]\n    B --&gt; B1[\"用户完成核心任务（首单价）\"]\n    C --&gt; C1[\"留存率\"] & C2[\"复购率\"] & C3[\"xx时间段活跃\"] & C4[\"分享UV数、次数\"]\n    D --&gt; D1[\"付费行为\"]\n    E --&gt; E1[\"K因子/NPS\"]\n\n    %% 样式优化\n    style AARRR fill:#F0F8FF,stroke:#4682B4\n\n\n\n\n\n\n\nK-factor是用来衡量产品病毒式传播能力的指标。它告诉我们平均每个现有的用户能够带来多少新用户。\n\n计算公式：（每个用户发送的邀请数）*（邀请的转化率）\n大于1意味着用户会自然增长，因为每个用户带来的新用户不止一个。这通常是产品获得病毒式增长的标志；小于1意味着产品需要通过其他营销手段来获取新用户。\n\nNPS(Net Promoter Score)是衡量客户忠诚度和推荐意愿的指标。\n\n通过询问客户“有多大程度上愿意向朋友或者同事推荐产品”来衡量。根据得分，用户被分为三类：\n\n推荐者（Promoters）：9-10分，是忠实且热情的用户\n被动者（Passives）：7-8分，对产品满意但不热情，容易被竞争对手吸引\n贬损者（Detractors）：0-6，对产品不满，可能传播负面口碑\n\n最终分数：NPS = （推荐者百分比）-（贬损者百分比）\n\n\n\n\n\n\n\nmindmap\n  root((商品价值 Goods value （货）))\n    维度\n      业态（食品、服装、美妆、数码、家居..）\n      品类（生鲜、女装、护肤、手机、床品..）\n      商品品牌\n      商家/店铺\n      SKU（Stock Keeping Unit）库存量单位\n        代表了商品的最小可售卖单位\n        每个SKU都有自己独特的编码，以区分商品的每一个具体属性。\n          一件“红色M码的T恤”\n      SPU（Standard Product Unit）标准化产品单位\n        代表了具有共同属性的商品的集合，是商品的抽象单位。\n        一个SPU可以包含多个SKU\n          “红色T恤”\n    指标\n      价格 Price\n      折扣率 Discount rate\n      销售量 Sales volume\n      销售金额 Sales amount\n      X 客户价值\n        商品为客户带来的价值\n          功能价值\n          情感价值\n          经济价值\n          时间价值\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((销售转化 Sales conversion))\n    维度\n      顾客/用户\n      商家/店铺\n    指标\n      各种行为 DAU\n      各种行为 转化率 Conversion rate\n      各种行为 商品数\n      各种行为 商品金额 Total amount of goods\n    行为漏斗\n      登录 Log in\n      曝光商品\n      浏览商品 Browse products\n      添加购物车 Add to cart\n      下单 Place orders\n      支付 Pay\n      退款 Refund\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((市场营销 Marketing))\n    维度\n      商家 Merchant\n      品牌 Brand\n      广告位 Ads location\n      活动类型 Campaign\n      优惠券类型 Coupon\n    指标\n      点击通过率 CTR (Click Through Rate)\n      每用户点击成本 CPC (Cost Per Click)\n      千人展现成本 CPM (Cost Per Mille)\n      投资回报率 ROI (投入产出比)\n      各种行为转化率\n      优惠券核销率、杠杆率 Coupon use rate\n      曝光/触达 Exposure\n    行为\n      访问平台 Access\n      新用户注册 Register\n      新用户首单交易成功 First order\n      营销商品交易成功 Marketed goods be purchaseds\n\n\n\n\n\n\n\n\n3.2.2 关键电商指标\n\n3.2.2.1 电商销售方面指标\n  这些指标侧重于：运营和改进电子商务商店、在线销售和支付以及增加的收入。\n一、转化率\n  访问网站并查看产品后购买的客户数量。代表了基于客户查看产品 的实际销售额。将其与页面浏览量、平均订单价值和流量来源进行比较，可以更深入地了解用户行为。\n二、毛利率\n  实际利率。\n三、平均订单价值(AOV)\n  平均客户订单的货币价值。还需要跟踪平均放弃订单价值(AAOV)，即在后买的结账或购物车阶段放弃的订单的平均价值。从整体上跟踪AOV，然后按设备类型、平台、流量来源进行细分。确定AOV最高的客户来源可以帮助我们开展更多高投资回报率的营销活动。\n四、每次获取成本\n  获得新用户的成本。包括广告成本、电子邮件活动、提供的折扣以及实际向客户进行销售所需的任何其他费用。可以了解真正获得付费客户需要付出的成本。可以与许多其他指标进行比较，包括平均订单价值、流量、客户生命周期价值等等，以了解赢得客户的成本。\n五、购物车放弃率\n  指将商品添加购物车后放弃购买的客户百分比。添加到购物车的商品数量、添加到购物车的商品价值以及他们购物的时间也都很重要。通过跟踪此指标，可以深入了解有多少客户对产品感兴趣但是没有继续购买。通过将其与此列表中的其他指标进行比较，可以制定降低放弃率并吸引更多客户进行销售的营销方案。\n六、结账放弃率\n  启动结账然后放弃购买的客户的百分比。这比购物车放弃更近一步，这以为这我们花费了更多的精力来让他们达到那个阶段。跟踪这个指标为我们提供了有关客户准备购买后未完成交易的具体信息。\n七、客户终身价值（复购）\n  客户终身价值(CLV)是作为用户的每个人的整个生命周期中平均赚取的收入金额。它本质上分解了一个客户对于我们来说的平均价值，并区分了现在购买200元的客户好在未来五年内购买100元产品10次的客户—–哪一个实际上对我们更有价值。这个指标使得我们深入了解每个客户对我们的价值。将其直接与客户获取成本、转化率、流量进行比较，以了解营销和客户获取活动的投资回报率。\n八、广告支出收入\n  将收入除广告成本，可以获得基于广告成本的平均回报收入的比率，该值是我们从每笔广告费中赚取的金额。跟踪它，使得我们根据当前成本和收入衡量赚取收入的平均广告成本。我们可以使用它来深入了解让客户完成购买需要花费多少广告费用。我们致力于通过尝试新的、更有效的广告方法来提高广告的投资回报率。\n\n\n3.2.2.2 用户体验方面指标\n  这些指标侧重于：用户如何使用我们的产品并与之互动、服务性能和速度、跨设备类型和平台的完善服务以及网站流量。\n九、设备类型\n  按照设备类型细分，以进一步了解哪些设备更频繁地使用，并针对每种设备类型定制网站的用户体验。跟踪这个指标可以为每个平台构建移动优化体验。尝试在不同设备类型之间保持一致的流程，但在不同设备（移动设备、网络和平板电脑）上测试性能，以了解客户的购买方式以及那种设备的工作效率最高。\n十、网站速度\n  网站速度和结账加载时间对于维护和吸引电子商务网站上的客户非常重要。电子商务平台的性能、效率和速度是购物者体验的核心。监控页面的速度，特别注意与购物车和结账相关的页面。\n十一、客户参与\n  客户对服务的参与程度，通常使用反应、分享和订阅来衡量。客户越活跃、越感兴趣，就越有可能购买、分享。我们可能需要跟踪的包括：用户在商店页面上停留的时间、用户最倾向点击每个页面的哪些区域、访问网站后再次访问的比率、通过社交渠道分享的用户、关注一些实时营销渠道并不取消订阅的用户等等。跟踪这个指标可以衡量用户在产品体验中的活跃程度和沉浸程度，因为这种活动和兴趣可以转化为忠诚度和收入。\n十二、跳出率\n  指仅访问一个页面后突然离开网站的客户比例。这通常说明存在着严重的用户体验问题，例如页面加载缓慢、外观或者导航延迟，也可能是营销定位不佳的迹象，因为广告所带来的客户没有在网站或待售产品中找到价值。我们使用跳出率来激励提高网站或应用程序的粘性。制定策略以降低跳出率，让更多的客户对产品感兴趣，建立客户忠诚度并引导购买。\n\n\n3.2.2.3 客户支持与满意度方面指标\n  这些指标侧重于：客户需要哪些支持方法、何时将用户连接到支持的最佳实践，以及捕获有关平台的有用反馈。\n十三、客户调查结果和反馈\n  定期进行客户调查并获得反馈，尤其在网站发生更改或者引入新功能时。愿意留下反馈的客户百分比是衡量客户对应用和产品感兴趣的一个指标。用户没有离开去并一个电子商务网站，而是给出反馈并希望得到改善。\n十四、客户评论\n  了解客户想法、需求。\n十五、客户联系方式（电话、邮箱）\n  注意用户最常使用的渠道。\n十六、平均工单解决时间\n  也成为服务级别协议时间(SLA)。跟踪平均SLA以及从工单创建到解决（打开到关闭）的平均时间。缩短平均响应时间意味着首次购物者将有可能重复购买。\n\n\n3.2.2.4 营销方面指标\n  这些指标侧重于：网站流量、客户参与方法和曝光度。\n十七、流量来源\n  确定顾客来源的主要渠道，以帮助改进营销和广告。来源包括付费广告、自然搜索网站、推荐、直接输入网页等等。分析以利用最佳渠道。加倍关注被证明有效的流量来源，并减少对流量产生最低的来源的工作量。\n十八、流量\n  以用户以及用户访问时间来衡量。可以作为一个整体来研究，也可以细分为更具体的一些指标，例如每次访问的页面的浏览量、网站停留时间、跳出率、新客户和回头客。衡量流量峰值以及平均值，并将这些数据与电商销售指标结合，以得出有关转化率、放弃和投资回报率的观点。\n十九、社媒参与度（关注、参与、分享）和浏览量\n  提供直接的沟通渠道。利用这种交流与客户建立关系，从而培养未来的忠诚用户；并帮助制定的社交媒体策略，提升影响力。进一步，虽然病毒式的传播可能具有价值，但是建立稳定。忠诚的读者群是建立可持续增长和可靠收入来源的更好方法。\n\n\n\n3.2.3 如何选择KPI\n  使用SMART方法。\n\n3.2.3.1 S.Specific\n  KPI必须清晰、明确，不能模糊不清。不能是模糊的“提高销售额”，而应该说“将本季度的线上销售额提高10%”。\n\n\n3.2.3.2 M.Measurable\n  必须是可以量化，可以被追踪、衡量的。比如“新增500个用户”。\n\n\n3.2.3.3 A.Achievable\n  必须显示可达成，不可假大空。\n\n\n3.2.3.4 R.Relevant\n  与现实业务关联。\n\n\n3.2.3.5 T.Time-bound\n  必须有明确的截止日期。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>行业指标梳理</span>"
    ]
  },
  {
    "objectID": "01metrics.html#短视频short-video",
    "href": "01metrics.html#短视频short-video",
    "title": "3  行业指标梳理",
    "section": "3.3 短视频Short Video",
    "text": "3.3 短视频Short Video\n\n3.3.1 短视频平台的生产机制\n  短视频平台用算法和激励制造出流量繁荣的假象，但背后创作者、用户和生态本身都在被慢慢消耗，这种机制既让平台看起来很繁荣，但是暗中积累“内伤”。如下图所示：\n\n\n\n\n\nflowchart TD\n    A[用户发布内容] --&gt; B[平台算法分发]\n    B --&gt; C[初始曝光量]\n    C --&gt; D[用户互动数据收集&lt;br&gt;（点赞/评论/转发/停留时长）]\n    D --&gt; E{数据表现如何?}\n    E --&gt;|高| F[平台增加曝光]\n    E --&gt;|低| G[平台减少曝光]\n    F --&gt; H[创作者获得更多流量和收益]\n    G --&gt; I[创作者流量下降、收益减少]\n    H --&gt; J[创作者正反馈：继续创作或加大投入]\n    I --&gt; K[创作者负反馈：焦虑/迎合算法]\n    J --&gt; L[内容同质化、创作压力增加]\n    K --&gt; L\n    L --&gt; B\n\n\n\n\n\n\n\n平台的算法分发决定了创作者的生存空间\n创作者为了流量、收益等等不断生产内容\n算法让大家卷到内容越来越同质化，最终影响创作生态\n\n\n\n3.3.2 内容创作\n\nUGC（User-Generated Content，用户生成内容），它指的是由品牌官方、专业机构、行业专家或拥有专业技能的创作者所制作的内容。主要形式包括：\n\n原创短视频：这是最基本的形式。用户通过拍摄、剪辑和配乐，创造出各种类型的原创内容，如日常生活分享、才艺展示、知识科普等。\n挑战与热点话题：平台会发起或用户自发形成各种挑战（Challenge）和热点话题，用户通过使用特定的 BGM、滤镜或模板来参与，这会产生大量的 UGC 并形成病毒式传播。\n合拍与二次创作：用户可以通过“合拍”、“Stitch”等功能，对其他用户的视频进行再创作。这种互动模式鼓励了用户之间的交流，并不断产生新的内容。\n评论与弹幕：用户在视频下方的评论和弹幕，也属于 UGC 的一种。它们是用户与内容互动、表达观点的直接方式，有助于形成社区氛围。\n\n\n  在短视频平台，UGC不仅仅是内容的来源，更是一种社交货币和用户参与感的体现。正是因为人人都可以成为创作者，才使得这类平台能够迅速积累海量内容和用户。\n\nPGC（ Professional-Generated Content ，专业生成内容），它指的是由品牌官方、专业机构、行业专家或拥有专业技能的创作者所制作的内容。PGC通常具有较高的制作水准、更严谨的知识性或更强的权威性。\nOGC（ Occupationally-generated Content ，职业生成内容），这个概念用来描述介于 UGC（用户生成内容）和 PGC（专业生成内容）之间的一种内容形态。\n\n生产者：OGC 的创作者通常是独立的专业人士、行业 KOL (意见领袖)、或签约的媒体内容创作者。他们依靠内容创作作为职业，具有一定的专业知识和制作能力。\n特点：OGC 往往拥有比 UGC 更高的制作水准和专业性，但又比 PGC 更加独立和中立，不完全代表品牌官方的立场。\n作用：OGC 在内容营销中扮演着重要的角色，它能以更客观、更具影响力的视角来传递信息，往往能获得消费者的信任。\n举例：品牌邀请一位头部博主拍摄的付费测评视频；一位专业的游戏主播制作的游戏攻略视频；一个独立的影评人撰写的影评文章。\n\n\n\n\n\n\n\n\n\n\n\n\nUGC和PGC的区别在于有无专业的学识、资质，PGC的生产创作主体在所共享内容的领域具有一定的知识背景和工作资历，UGC则没有。\nPGC和OGC的区别在于是否领取相应报酬，PGC的生产创作主体往往是出于“爱好”，义务的贡献内容，不收取报酬；而OGC是以职业为前提，其创作内容属于职务行为，获取报酬。\nUGC和OGC没有交集，在一个平台（网站）上，用户和提供商总是相对的，既是该平台的用户也是该平台的提供商的角色可能有，但属于极少的群体。\nPUGC（Professional User Generated Content，专业用户生产内容），以UGC形式产出的相对接近PGC的专业内容。PUGC模式是UGC、PGC模式发展中逐渐演化出的一种全新生产模式，率先由国内数字音频领域提出，后延伸到视频内容生产领域，被认为是“互联网短视频长远发展的趋势”。\n\nPUGC短视频既满足了用户对专业化、高品质内容的需求，又达到了贴近性且个性化的效果，满足了短视频用户的多种需求，极大程度提升了短视频平台内容的品味。\nYouTube与B站目前是全球PUGC较为集中的社交型视内容网站，其中B站已经在内容战略上明确转向“建设PUGV( Professional User Generated Video)社区”。\n\nPUGC与PGC、UGC的关系\n\n从发展阶段上来说，PUGC是UGC、PGC模式在深度发育后为规避各自发展瓶颈而协商整合的结果。\n\nPGC导向的长视颏（爱优腾）与UGC导向的短视频的平行发展格局已经确立，但两种生产方式的固有弊病也在逐渐极化：UGC尽管建构出生产的民主性与圈层化，但非专业性制作和扁平叙事造成了视觉品相的降低和叙事深度的缺失；PGC的专业研创保证了视觉与内容品质，但作为融媒体时代重要标志的个性化需求却被抑制。\n因而，业务界开始寻求两种模式的组合：专业用户生产内容（PUCC）由此产生。这种模式要求保留内容作者的个性，同时对内容生产全流程的专业性进行把控，不仅维系了内容作者的核心性，同时在其生产链中植入了“专业化”的模块。\n\n从生产模式来看，PUGC的生产链已经与传统UGC、PGC逐渐分异。目前，以B站为代表的PUGC视频生产模式的主流策略基本采用几种方式：\n\n以UP主本人为核心的视频内容：利用专业团队辅助内容生产，以内容作者共同体的身份参与平台发布流程\n专业视频内容团队直接生产内容，以作者身份在平台发布\nUP主本人通过平台专业技能培训计划或自行学习，生产专业内容在平台发布\n\n由此可见，PUGC的生产链已经与传统UGC、PGC逐渐分异：内容作者仍位于生产链的中心位置，但“专业化模块”以各种形式介入生产流程。这一独立的生产模式的形成对既有的UGC 、PGC模式研究提出了新的要求，尤其对PUCC模式语境下的作者核心性和专业化方面的研究亟需展开。\n\nMGC（Machine Generated Content，机器生产内容或技术生产内容），指万物互联和全时在线的数据通过数据挖掘和智能算法生成海量的传感器资讯。如MGC新闻就是运用现代化的人工智能技术，由机器智能生产的新闻。通过摄像头、传感器、无人机等设备获取音视频线索，经由内部视频图像识别功能，让机器智能理解内容并做价值判断。随后与已有数据相关联，对语音语义进行检索和排列组合，智能生产审核新闻稿件，再经视频语音合成编辑、数据可视化系列过程，最终生成富媒体新闻。新华社发布的首条MGC视频新闻由媒体大脑中的“2410（智能媒体生产平台）”创造。\n\n\n\n3.3.3 生产消费\n待补充\n\n\n3.3.4 Mindmap\n\n\n\n\n\nmindmap\n  root((Short video))\n    平台流量 Web traffic\n    视频 \n    作者Creator 内容生产\n    用户User 内容消费\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((平台流量 Web traffic))\n    维度\n      时段\n      PC/Mobile\n      不同板块\n      页面位置\n        主页、推荐页、视频详情页..\n    指标\n      累计注册人数\n      新注册用户数\n      PV、UV、DAU、WAU、MAU、用户粘性（DAU/MAU）\n      人均每日使用时长\n      启动次数分布\n      收入\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((视频))\n    维度\n      内容类型 Content\n      展现形式\n        图文、录屏、情景剧、真人口述\n      发布渠道 Post days\n      发布天数 Post days\n      视频时长 Video length\n    指标\n      播放指标\n        累计播放PV、UV\n        分时、分日播放量 play amount\n        人均播放次数 Number of plays per person\n        平均播放时长 Average play time\n        ☆完播率 Completion rate\n        跳出率 Bounce rate\n      互动指标\n        互动量\n        互动行为间比率: 播放比、赞赞比\n        互动行为转化率: 互动人数/播放人数\n          如粉丝转化率\n    互动行为\n      评论、点赞、转发、分享、收藏、@人、保存、弹幕、关注、搜索、踩、举报、不感兴趣\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((作者Creator（内容生产）)\n    维度\n      创作者主体类型\n        个人\n        团队\n        企业\n      头部KOL类型\n        娱乐明星\n        幽默搞笑\n        美食\n        音乐\n        萌宠\n        游戏\n      内容生产模式\n        UGC （User Generated Content）\n        PGC （Professionally Generated Content）\n        OGC （Occupationally Generated Content）\n    指标\n      粉丝量 Followers\n      播放量 Views\n      被互动量 Interactions\n      内容收入\n    聚合指标\n      内容生产者总数\n      内容生产者占用户比\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((用户User（内容消费）)\n    维度\n      新老客\n      年龄层\n      性别\n      城市\n      操作系统\n        iOS\n        Android\n      注册来源\n        搜索、推荐、落地页、运营活动\n      网络\n        WI-FI\n        2345G\n      运营商\n        移动、联通、电信\n      注册时长\n    指标\n      日均、周均观看时长 Average daily use time\n      周活跃天数 Weekly active days\n      留存率 Retention rate\n      各种互动数\n      关注数\n      X内容\n        兴趣关键词\n    互动行为\n      评论Comment\n      点赞Like\n      转发Repost\n      分享Share\n      收藏、@人\n      保存\n      弹幕\n      关注\n      踩\n      举报\n      不感兴趣\n      求更新",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>行业指标梳理</span>"
    ]
  },
  {
    "objectID": "01metrics.html#直播live",
    "href": "01metrics.html#直播live",
    "title": "3  行业指标梳理",
    "section": "3.4 直播Live",
    "text": "3.4 直播Live\n\n\n\n\n\nmindmap\n  root((Live))\n    平台流量\n    直播复盘\n    观众画像\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((平台流量))\n    维度\n      时段\n      PC/Mobile\n      不同模块\n      页面位置\n        主页、推荐页、详情页..\n    指标\n      累计注册人数\n      新注册用户数\n      PV、UV、DAU、WAU、MAU、用户粘性（DAU/MAU）\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((直播复盘))\n    维度\n      直播类型\n        购物、游戏、聊天、语音..\n      直播时间段\n        上午、下午、晚上\n      直播时长\n    指标\n      单场GMV\n      分时观看PV、UV\n      累计观看PV、UV\n      最高在线人数 PCU\n      平均在线人数ACU\n      千次曝光成交金额GPM\n      观看--下单转化率\n      单个观看UV价值 ARPU: 单个看播用户成交金额\n      下单用户平均UV价值 ARRPU\n      新观众占比、粉丝占比\n      观众平均停留时长\n      互动PV/UV\n      付费率\n      新增粉丝数\n      场间掉粉数\n      订单笔数\n      订单总金额\n      订单商品种类\n      商品\n        商品点击次数\n        带货商品数\n        动销商品数\n        商品点击人数\n        \n      \n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((观众画像))\n    维度\n      新观众、老观众\n      年龄\n      性别\n      兴趣\n      操作系统\n        安卓、ios\n      注册来源\n        搜索、推荐、落地页、运营活动...\n      观看来源\n        直播推荐、同城推荐、关注、PK、搜索、直播榜单\n      观看渠道\n        移动端、PC端\n      观看类型\n        购物、游戏、聊天、语音...\n    指标\n      日均/周均观看人数 \n      观看直播场数\n      留存率\n      订单数\n      消费金额\n      ARPU/ARPPU\n      互动次数\n      互动转化率\n    互动行为\n      评论、点赞、转发、分享、收藏、@他人、保存、弹幕、关注、踩、举报、不感兴趣",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>行业指标梳理</span>"
    ]
  },
  {
    "objectID": "01metrics.html#社交媒体social-media",
    "href": "01metrics.html#社交媒体social-media",
    "title": "3  行业指标梳理",
    "section": "3.5 社交媒体Social Media",
    "text": "3.5 社交媒体Social Media\n\n\n\n\n\nmindmap\n  root((Socical Media))\n    平台流量\n      维度\n      指标\n    用户\n      维度\n      指标\n      行为\n    大V\n      维度\n      指标\n    内容\n      维度\n      指标\n    热点事件\n      维度\n      指标\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((平台流量))\n    维度\n      时间段\n      mobile/PC\n      不同模块\n    指标\n      累计注册人数\n      新注册人数\n      UV/PV/DAU/WAU/MAU/用户粘性\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((用户))\n    维度\n      新用户/老用户\n      年龄\n      性别\n      兴趣爱好\n      城市\n      操作系统\n    指标\n      周活跃天数\n      日均/周均访问时长\n      留存率\n      热点关注人数\n      行为数\n    行为\n      创作行为\n        发帖（单独或参与话题）\n        参与话题\n        上传图片/视频\n      互动行为\n        评论、点赞、收藏、分享、转发、@他人、保存、搜索、关注、弹幕、踩、不感兴趣、举报\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((大V))\n    维度\n      KOL类型\n        明星网红政务服务\n      内容类型\n        明星、娱乐八卦、美食、萌宠、影视、体育、游戏、音乐、旅游。政务、幽默搞笑\n        内容生产模式\n          PGC\n          OGC\n          UGC\n          PUGC\n    指标\n      粉丝量\n      互动量\n      阅读量\n      播放量\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((内容))\n    维度（内容形式）\n      图文、视频、直播\n    指标\n      发布内容的数量\n      粉丝量\n      阅读量\n      播放量\n      互动率\n      涨粉率\n\n\n\n\n\n\n\n\n\n\n\nmindmap\n  root((热点事件))\n    维度（事件性质）\n      娱乐、政治...\n    指标\n      阅读量\n      讨论度\n      互动率",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>行业指标梳理</span>"
    ]
  },
  {
    "objectID": "01metrics.html#风控",
    "href": "01metrics.html#风控",
    "title": "3  行业指标梳理",
    "section": "3.6 风控",
    "text": "3.6 风控\n\n3.6.1 如何识别作弊用户\n  一般是爬虫或者渠道伪造的假用户\n\n分类问题可以用机器学习的分类算法\n\n渠道特征：渠道、渠道次日留存率、渠道流量、各种比率特征\n环境特征：设备（家用户以低端机为主）、系统（刷量的一般系统更新比较慢）、wifi使用情况、使用时间、来源地区、ip是否是 blocked\n用户行为特征：访问时间、访问时长、访问页面、使用间隔、次日留存、活跃时间、页面跳转行为（假用户的行为要么多于一致，要么过于随机）、页面使用行为\n异常特征：设备号异常，ip异常（异地访问）、行为异常（突然大量点击广告、点赞）、数据包不完整\n\n\n\n\n3.6.2 恶意刷单检测\n\n机器学习分类算法\n\n商家特征：商家历史销量、信用、产品类别、发货快递公司等\n用户行为特征：用户信用、下单量、转化率、下单路径、浏览店铺行为、支付账号\n环境特征（主要是避免机器刷单）：地区、ip、手机型号等\n异常检测：ip地址经常变动、经常清空cookie信息、账号近期交易成功率上升等\n评论文本检测：刷单的评论文本可能套路较为一致，计算与已标注评论文本的相似度作为特征\n图片相似度检测：同理，刷单可能重复利用图片进行评论",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>行业指标梳理</span>"
    ]
  },
  {
    "objectID": "02ABTest.html",
    "href": "02ABTest.html",
    "title": "4  ABTest",
    "section": "",
    "text": "4.1 概览\n本章介绍AB测试。AB测试（也称为随机对照试验 - RCT, Randomized Controlled Trial）是一种用于因果推断的实验设计方法。其核心在于通过随机分配将受试单元（用户、会话、页面访问等）分配到不同的处理组（通常是A：对照组/Baseline，B：新方案组），在控制其他变量（通过随机化）的前提下，比较不同处理对特定目标指标的影响，从而决定哪个更优。\n本章参考了@knuth84",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ABTest</span>"
    ]
  },
  {
    "objectID": "02ABTest.html#理论基础",
    "href": "02ABTest.html#理论基础",
    "title": "4  ABTest",
    "section": "4.2 理论基础",
    "text": "4.2 理论基础\n\n4.2.1 因果推断的基石：潜在结果框架与随机化\n\n潜在结果框架（Neyman-Rubin Causal Model）：\n\n定义：对于每个实验单元\\(i\\)（用户、会话等），定义两个潜在结果：\n\n\\(Y_i(1)\\)：单元\\(i\\)接受处理\\(B\\)（干预）时的结果\n\\(Y_i(0)\\)：单元\\(i\\)接受处理\\(A\\)（对照）时的结果\n\n个体处理效应：\\(\\text{ITE} = \\tau_i = Y_i(1) - Y_i(0)\\)\n根本问题：对于任何单元\\(i\\)，我们只能观察到\\(Y_i(1)\\)或\\(Y_i(0)\\)，永远无法同时观测两者，观察到的结果\\(Y_i^{obs} = Z_i * Y_i(1) + (1 - Z_i) * Y_i(0)\\)，其中\\(Z_i\\)是指示变量，\\(Z_i=1\\) 表示分配到\\(B\\)组，\\(Z_i=0\\) 表示分配到\\(A\\)组)。\n目标：估计平均处理效应\\(\\text{ATE} = \\tau = E[\\tau_i] = E[Y_i(1)-Y_i(0)]=E[Y(1)]-E[Y(0)]\\)\n\n随机化\n\n\n关键假设（Ignorability/Unconfoundedness）：通过完全随机分配，我们确保处理分配\\(Z_i\\)独立于潜在结果，即\\(Y_i(1),Y_i(0) \\perp Z_i\\)，这意味着\\(E[Y_i(1) | Z_i=1] = E[Y_i(1) | Z_i=0] = E[Y_i(1)]\\)（同理于\\(Y_i(0)\\)）。\n无偏估计量：基于观测数据，ATE 的一个简单无偏估计量是组间均值差\\[\\hat{τ}_{DiM} = \\hat{E}[Y^{obs} | Z=1] - \\hat{E}[Y^{obs} | Z=0] = \\bar{Y}_B - \\bar{Y}_A\\]\n\n证明无偏性： \\[E[\\hat{τ}_{DiM}] = E[\\bar{Y}_B - \\bar{Y}_A] = E[\\bar{Y}_B] - E[\\bar{Y}_A] = E[Y(1) | Z=1] - E[Y(0) | Z=0]\\]（根据观测数据定义）\n由于随机化（\\(Y_i(1),Y_i(0) \\perp Z_i\\)），有\\(E[Y(1) | Z=1] = E[Y(1)]\\)且\\(E[Y(0) | Z=0] = E[Y(0)]\\) 因此\\(E[\\hat{τ}_{DiM}] = E[Y(1)] - E[Y(0)] = ATE\\)\n\n协变量平衡 (Covariate Balance): 随机化也确保所有观测到的\\(X\\) 和未观测到的 \\(U\\) 混杂因素（Confounders）在组间的分布是相同的（渐近意义上）： \\(F(X | Z=1) = F(X | Z=0)\\)和\\(F(U | Z=1) = F(U | Z=0)\\)\n\n这是实现\\(Y(1),Y(0) \\perp Z\\)的关键保障。AA测试检查的就是观测到的 X是否平衡。\n\n\n4.2.2 假说检验\n\n核心框架\n\n\n原假设\\(H_0\\)：\\(ATE = 0\\)或等价的\\(\\mu_A = \\mu_B\\)（总体均值相等）或\\(p_A = p_B\\)（总体比例相等）。\n备择假设\\(H_1\\)：\\(ATE \\neq 0\\)（双尾）或\\(ATE&gt;0\\)或\\(ATE&lt;0\\)（单尾）。\n检验统计量\\(T\\)：构造一个统计量，其分布在\\(H_0\\)成立时已知（或渐进已知）。\n\\(P-value\\)：\\(p=P\\left(|T| \\geq \\left|t_{obs}\\right| \\middle| H_0\\right)\\)，即\\(H_0\\)成立时，观察到当前统计量\\(t_{obs}\\)甚至于更极端值的概率。\n决策：若\\(p&lt;\\alpha\\)，\\(\\alpha\\)为我们预设的显著性水平，则拒绝\\(H_0\\)。\n\n\n连续性指标：双样本\\(t\\)检验\n\n  例如平均订单金额、会话时长。\n\n假设：\n\n独立性Independent Samples\n正态性Normality：每组数据近似正态分布（或样本量足够大，依赖CLT）\n方差齐性Homoscedasticity：\\(\\sigma_A^2 = \\sigma_B^2 = \\sigma^2\\)\n\n检验统计量：\n\n\\[t = \\frac{(\\bar{Y}_B - \\bar{Y}_A) - 0}{s_p \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}}\\] 其中\\(s_p² = \\frac{(n_A - 1)s_A² + (n_B - 1)s_B²}{n_A + n_B - 2}\\)是合并方差估计量 (Pooled Variance Estimator)，\\(s_A^2\\)，\\(s_B^2\\)是样本方差，\\(n_A\\)，\\(n_B\\)是样本量。\n\n分布：在\\(H_0\\)和假设成立的条件下，\\(t \\sim t_{df}\\)，自由度\\(df = n_A+n_B-2\\)\n方差不齐 (Welch’s t-test):若方差不齐，使用调整后的统计量和自由度， \\[t = \\frac{\\bar{Y}_B - \\bar{Y}_A}{\\sqrt{\\frac{s_A²}{n_A} + \\frac{s_B²}{n_B}}}\\]，自由度为\\(df ≈ \\frac{(\\frac{s_A²}{n_A} + \\frac{s_B²}{n_B})²}{\\frac{(s_A²/n_A)²}{n_A - 1} + \\frac{(s_B²/n_B)²}{n_B - 1}}\\)\n\n\n比例型指标：双样本比例检验（\\(Z\\)检验）\n\n  例如点击率、转化率。\n\n假设：\n\n独立性\n大样本：\\((n_A p_A &gt; 5, n_A (1-p_A) &gt; 5, n_B p_B &gt; 5, n_B (1-p_B) &gt; 5)\\)，确保二项分布近似正态。\n\n检验统计量（基于合并比例）： \\[Z = \\frac{\\hat{p}_B - \\hat{p}_A}{\\sqrt{\\hat{p}(1-\\hat{p}) (\\frac{1}{n_A} + \\frac{1}{n_B})}}\\] 其中\\(\\hat{p} = \\frac{X_A + X_B}{n_A + n_B}\\)，\\(X_A\\)，\\(X_B\\)是成功的次数，是\\(H_0(p_A =p_B = p)\\)下\\(p\\)的合并估计量。\n分布：在\\(H_0\\)和假设成立的条件下，\\(Z\\sim N(0, 1)\\)（渐近）。\n基于独立方差（更常用且推荐）：\n\n\\[Z = \\frac{\\hat{p}_B - \\hat{p}_A}{\\sqrt{\\hat{p}(1-\\hat{p}) (\\frac{1}{n_A} + \\frac{1}{n_B})}}\\]，这个版本不依赖与\\(H_0\\)下\\(p_A=p_B\\)的假设，在构建置信区间时更加自然，检验功效稍低但是更稳健。渐近分布同样是\\(N(0, 1)\\)。\n\n计数型指标   例如人均点击次数。常假设服从泊松分布，使用基于泊松回归或负二项回归的检验（处理过离散问题）。\n置信区间（CI）\n\n\n概念：基于样本数据构造一个区间\\((L, U)\\)，使得我们要估计的参数\\(\\theta\\)（我们这里是\\(ATE\\)）落在这个区间的概率是\\(1-\\alpha\\)，即\\(P(L\\leq \\theta \\leq U) = 1-\\alpha\\)。频率学派的解释是，重复多次试验，每次构造一个CI，那么大约\\(1-\\alpha\\)的CI会包含真实的\\(\\theta\\)。以下均以双尾检验为例。\n连续性指标（差异）： \\[(\\bar{Y}_B - \\bar{Y}_A) \\pm t_{df, 1-\\alpha/2} \\times SE(\\bar{Y}_B - \\bar{Y}_A)\\] 其中 \\(SE(\\bar{Y}\\_B - \\bar{Y}\\_A) = \\sqrt{\\frac{s_A²}{n_A} + \\frac{s_B²}{n_B}}\\)（Welch)）或\\(s_p \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}\\)（Pooled）。\n比例型指标（差异）：\\[(\\hat{p}_B - \\hat{p}_A) \\pm Z_{1-\\alpha/2} \\times \\sqrt{\\frac{\\hat{p}_A(1-\\hat{p}_A)}{n_A} + \\frac{\\hat{p}_B(1-\\hat{p}_B)}{n_B}}\\]\n解读：如果95%CI不包含0，则双尾验证在$$显著性水平下显著。CI宽度反映了估计的精确度。\n\n\n\n4.2.3 统计功效与样本量计算\n\n定义与公式\n\n\nI类错误（\\(\\alpha\\)）：\\(H_0\\)为真时，错误地拒绝\\(H_0\\)。也就是说宣称有差异实际没有。\nII类错误（\\(\\beta\\)）：\\(H_1\\)为真时，没有拒绝\\(H_0\\)。也就是说实际上有差异但是没有检测到。\n功效（Power）\\(1-\\beta\\)：\\(P(\\text{Reject } H₀ | H₁ \\text{ is true})\\)。即当真实效应\\(\\delta = |ATE|\\)（或\\(|\\mu_B -\\mu_A|\\)，\\(|p_B - p_A|\\)）存在且等于最小期望检测效应（MDE）时，正确拒绝\\(H_0\\)的概率。换句话说，就是当处理B确实比A好（\\(H_1\\)为真）时，正确拒绝\\(H_0\\)的概率\\(1-\\beta\\)。\n影响功效的关键因素（以双样本\\(t\\)检验为例）：\n\n效应量（\\(\\delta\\)）:期望检测到的最小有意义的差异\\(\\delta = \\frac{|\\mu_B - \\mu_A|}{\\sigma}\\)，这是标准化效应量，Cohen’sd。\\(\\delta\\)越大，功效越高，\\(\\delta\\)越小，检测所需要的样本量越大。\n样本量（\\(n = n_A= n_B\\)）:\\(n\\)越大，功效越高，功效\\(\\propto \\sqrt{n}\\)\n显著性水平（\\(\\alpha\\)）：犯I类错误（假阳性）的概率。\\(\\alpha\\)越大，即允许更多假阳性，功效越高。\\(\\alpha\\)越小，所需要样本量越大。\n方差（\\(\\sigma^2\\)）：\\(\\sigma^2\\)越大，功效越低。指标本身的变异性越大，检测相同效应量所需的样本量越大（对于连续型指标）。\n基准比率（p_A）：对于比例指标，基准转化率影响方差（p(1-p)），在p=0.5时最大。\n\n样本量计算公式（双样本\\(t\\)检验，双尾，等样本量）：\n\n\\[n \\approx \\frac{2 (Z_{1-\\alpha/2} + Z_{1-\\beta})^2 \\sigma^2}{\\delta^2}\\]\n其中\\(Z_{1-\\alpha/2},Z_{1-\\beta}\\)是标准正态分布的分位数，\\(\\delta\\)是未标准化的效应量(\\(|\\mu_B-\\mu_A|\\))。这个公式推导基于\\(H_0\\)下的统计量\\(\\sim N(0, 1)\\)，\\(H_1\\)下的统计量\\(\\sim N(\\frac{\\delta}{\\sigma \\sqrt{2/n}}, 1)\\)，令两个分布的拒绝域边界相交即可解出\\(n\\)。\n\n比例型指标（双样本比例检验，双尾，等样本量）：\n\n\\[n \\approx \\frac{ (Z_{1-\\alpha/2} \\sqrt{2\\bar{p}(1-\\bar{p})} + Z_{1-\\beta} \\sqrt{p_A(1-p_A) + p_B(1-p_B)} )² }{\\delta²}\\] 其中\\(\\delta = |p_B-p_A|,\\bar{p} = \\frac{p_A+p_B}{2}\\)，推导类似，考虑\\(H_0\\)下方差基于\\(\\bar{p}\\)，\\(H1\\)下方差基于真实的\\(p_A\\)和\\(p_B\\)。\n\n\n4.2.4 方差估计的挑战（用户级随机化）\n\n问题核心：在用户级随机化的AB测试中，分析单元（如页面浏览PV，点击Click）与随机化单元（用户User）不一致。同一个用户的不同事件/行为不独立。\n后果：传统的方差估计公式（如\\(\\frac{s^2}{n}\\)）会严重低估真实方差，导致：\n\nCI过窄\n\\(p-value\\)过小，I类错误率（假阳性率）膨胀\n\n数学解释：\n\n假设有\\(m\\)个用户\\(i = 1...m\\)，用户\\(i\\)贡献\\(n_i\\)个观测值（如\\(PV\\)），总观测值\\(N = \\sum_i n_i\\)\n核心指标\\(Y\\)在用户\\(i\\)上的平均为\\(\\bar{Y}_i\\)\n组件差异估计量\\(\\hat{\\tau} = \\bar{Y}_B - \\bar{Y}_A\\)\n其真实方差为：\\(Var(\\hat{τ}) = Var(\\frac{1}{m_B} \\sum_{i \\in B} \\bar{Y}_i - \\frac{1}{m_A} \\sum_{j \\in A} \\bar{Y}_j)\\)，由于用户间是独立的，\\(Var(\\hat{τ}) = \\frac{Var(\\bar{Y}_i | B)}{m_B} + \\frac{Var(\\bar{Y}_j | A)}{m_A}\\)\n而传统方差估计（假设观测独立）为：\\(\\widehat{Var}_{naive}(\\hat{τ}) \\approx \\frac{s_B²}{N_B} + \\frac{s_A²}{N_A}\\)，其中\\(N_B = \\sum_{i \\in B} n_i\\)（B组总观测数），\\(s_B^2\\)是基于所有B组观测值计算的方差\n\\(\\widehat{Var}_{naive}\\)会系统性小于\\(Var(\\hat{\\tau})\\)，因为忽略了用户的内相关性。低估的程度取决于用户内相关性的强度和用户行为次数\\(n_i\\)的变异度。\n\n解决方案：\n\n\\(Delta\\) \\(Method\\)：推倒\\(\\hat{\\tau}\\)方差的理论表达式并进行估计。适用于特定指标类型（如人均指标）。\n聚类标准误（Cluster-Robust Standard Errors - CRSE）：将方差估计建立在随机化单元（用户）的层面。\n\n将每一个用户视为一个“聚类”\n计算每个用户\\(i\\)对\\(\\hat{\\tau}\\)的“得分”（Influence Function）或残差贡献\\(e_i\\)\n聚类标准误为： \\(\\widehat{Var}_{CR}(\\hat{τ}) = \\frac{m}{m-1} \\frac{m}{m_A m_B} \\sum_{i=1}^m (\\tilde{e}_i - \\bar{\\tilde{e}})^2\\)，其中\\(\\tilde{e}_i\\)是用户\\(i\\)的聚合残差贡献（具体形式取决于模型）。这是最常用且稳健的方法。\n\nBooststrap（聚类Booststrap）：对用户进行重抽样（而不是对观测值），保持用户的所有数据完整。每次重抽样后计算\\(\\hat{\\tau}\\)，用多次（B次）重抽样得到的\\(\\hat{\\tau}^{(b)}\\)的方差来估计\\(\\hat{\\tau}\\)。计算量大但是灵活。\n\n\n\n\n4.2.5 多重检验问题（Multiple Testing Problem）\n\n问题核心：同时进行\\(K\\)次独立的假设检验，每个检验的显著性水平都为\\(\\alpha\\)。那么至少出现一次假阳性（I类错误）的概率（族系错误率FWER,Family-Wise Error Rate）是\\[FWER = P(\\text{至少一个错误拒绝} | \\text{所有 } H₀ \\text{ 为真}) = 1 - (1 - α)^K ≈ Kα \\quad (\\text{当 } α \\text{ 很小时})\\]，即使\\(\\alpha = 0.05\\)，当\\(K\\)为10时，FWER约为0.4，假阳性率非常高。\nABTest中的来源：\n\n同时测试多个核心指标（\\(K&gt;1\\)）\n同时测试多个变体（A/B/C/D…测试，\\(K&gt;1\\)个比较）\n数据窥探（Peeking）：在实验运行期间多次查看结果并进行检验。每次查看都是一次独立的检验机会（\\(K\\)很大）。\n\n控制方法（待补充）\n\n\n\n4.2.6 进阶统计视角（待补充）\n  AB测试的统计学原理深植于因果推断的潜在结果框架，随机化是其无偏估计的基石。假设检验 (t/Z检验)提供决策依据，置信区间量化不确定性。功效分析确保实验可靠性，样本量计算是实验设计的核心。实践中必须警惕方差低估 (用户级相关性) 和多重检验膨胀，采用聚类标准误或校正方法。贝叶斯方法和序贯检验提供了替代视角和效率提升。理解异质性效应能挖掘更深价值。掌握这些原理，是设计和解读可靠AB测试的关键。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ABTest</span>"
    ]
  },
  {
    "objectID": "02ABTest.html#ab测试的流程与步骤",
    "href": "02ABTest.html#ab测试的流程与步骤",
    "title": "4  ABTest",
    "section": "4.3 AB测试的流程与步骤",
    "text": "4.3 AB测试的流程与步骤\n  ABtest其实就是控制变量法。为了评估测试和验证模型/项目的效果，在app/pc端设计出多个版本，在同一时间维度下，分别用组成相同/相似的群组去随机访问这些版本，记录下群组的用户体验数据和业务数据，最后评估不同方案的效果决定是否上线。\n\n4.3.1 1.明确目标与假设\n\n定义清晰的业务目标（如提升注册转化率、增加平均订单价值）。\n提出具体的、可证伪的统计假设（\\(H_0\\)和\\(H_1\\)）。\n确定期望检测的最小有意义效应量MDE\n\n\n\n4.3.2 2.确定目标指标与护栏指标\n\n核心指标（Primary Metrics）：直接反映实验目标的1-2个关键指标（如转化率、收入）\n\n例如：修改购买页面的主色调能够帮助用户购买率提升3%\n那么用户购买率就是我们关注的\n还需要关注一些新策略是否会对其他重要指标产生负面影响\n\n护栏指标（Guardrail Metrics）：监控实验潜在负面影响的指标（如页面加载时间、关键功能使用率、崩溃率）。确保优化核心指标不以牺牲其他重要方面为代价。\n\nOrganization Guardrail Metrics：新功能可能好但是加载慢；该付款界面UI对用户的下单单价不能有影响\nTrustworthy-related metrics：比如检查randomization，要用T-test或者卡方检验在查看A/B组的其他特征一致性\n\n探索性指标（Exploratory Metrics）：帮助理解用户行为变化，发现意外结果的辅助指标。\n\n\n\n4.3.3 3.实验设计\n\n单元选择（Unit of Diversion/randomization Unit）：决定随机化的最小单元（用户ID，设备ID，会话ID，页面访问）。选择时需要考虑指标计算（用户级指标需用户级分流）、用户多次体验（保持体验一致性）、样本独立性（避免干扰）。用户级分流最常见。\n分流比例（Traffic Allocation）：分配多少样本去A/B组。通常是50:50，这样统计效率最高。但也会根据风险、流量大小调整（如90:10，新方案流量少）。需要确保样本量足够。\n样本量计算（Sample Size Estimation）：基于\\(\\alpha, \\beta, MDE\\)，基准值（\\(p_A\\)或\\(\\sigma_A\\)）计算每组所需要的最小样本量/实验时长。这一点至关重要！样本不足会导致功效低（II类错误风险高），样本过大浪费资源和时间。\n分层与区组（Sractification&Blocking）：在随机化钱按重要特征（如国家、设备类型、用户新老）分层或区组，确保这些特征在组间均衡分布，提高统计精度（尤其当特征与指标强相关时）。\n触发与曝光（Triggering&Exposure）：明确那些用户会被纳入实验（所有的访问者？特定路径访问者？）。以及何时记录他们被“曝光”于实验条件、确保分析对象是真正“看到了”实验变化的用户，称为“曝光后分析”。\n\n  下面将具体举例进行介绍。\n\nWHO\n\n  AB实验实验需要控制变量，确保两组中只有一个不同的变量，其余变量一致。\n\n必须满足的条件：\n\n特征相同或相似的用户群组\n同一时间维度\n\n操作方法：\n\n利用用户唯一标识的尾号或者其他标识进行分类，如奇偶分为两组\n用一个hash函数将用户的唯一标识进行取模，分桶。可以将用户均匀地分到若干桶中，如分到100/1000个桶中，这样的好处就是可以进一步将用户打散，提高分组的效果。\n\n当然，如果有多个分组并行的情况的话，要考虑独占域和分享域问题。独占域指不同域之间的用户相互独立，交集为空。对于共享域，我们要进行分层。但是在分层中，下一层要将上一层的用户打散，确保下一层用户的随机性。\n实验对象：\n\n如果是双边市场的话，可以从用户、平台、生产者三方进行实验\n\n双边市场：指平台同时服务两类或多类相互依存的客户。例如，淘宝连接了买家和卖家，滴滴连接了乘客和司机，内容平台连接了用户和创作者。\n信息流实验：指的是围绕“信息”在用户和生产者之间流动的过程所进行的实验。推荐系统是其中的核心组成部分。\n用户（C端实验）\n\n是最常见的AB实验场景，直接面向用户\n产品策略：例如新功能上线，用户界面UI改版\n运营策略：比如推送通知的文案、活动页面设计\n客户端改版：例如APP的新版本、页面布局的调整\n核心目标：提升用户体验，提高留存度和活跃度\n\ncp/内容生产者（B端实验）\n\n面向内容生产者或者商家的产品和策略\n例如：内容池优化（让创作者更方便地上传内容）、创作者激励（新的分成机制）、黑产打击（识别和处理恶意内容）。\n旨在提升B端的生产效率、积极性，维护平台生态健康\n\n推荐实验（平台侧）\n\n面对：链接用户和CP的关键桥梁—推荐算法\n例子：自动训参（Auto-tuning，自动调整推荐算法的参数）、召回优化（提高找到用户可能喜欢的内容的效率）、排序优化（更好的对召回内容进行排序）、多目标优化（同时考虑点击率、停留市场、GMV等多个指标）、体验优化（减少广告干扰）、人群策略（针对特定人群提供定制化推荐）。推荐算法的效果直接影响着用户和CP两段的满意度。\n\n\n推荐实验常用试验方法：（未展开，有机会可以展开）\n\nABTest\n上线实验\nMAB实验\n在线寻参\n\n\n人群圈选方式（行为圈选、标签圈选、属性圈选）\n\n多层方案\n\n分流：用户分流是指按照地域、性别、年龄等等将用户均匀地分成几个组，1个用户只能出现在1个组中。\n\n适合互斥实验：实验在同一层拆分流量，且无论怎么拆分，不同组的流量是不会重叠的\n例如“安卓用户”，“只看北京用户”。很多情况中不同城市的用户的的情况会有很大差别\n问题：实际情况中，往往会上线多个实验。例如可能同时上线样式形态、广告位置策略、预估模型的实验。如果只按照分流模式来说，在每组实验放量10%的情况下，整体的流量只能同时开展10个实验。效率很低。为了解决这个问题，提出了用户分层、流量复用的方法。\n\n分层：同一份流量可以分布在多个实验层，也就是说同一批用户可以出现在不同的实验层，前提是各个实验层之间无业务关联，保证这一批用户都均匀地分布到所有的实验层中，达到用户正交的效果就可以，从而让实验流量复用。\n\n根据业务方人为定义一些分层–如：UI层、推荐算法层\n每一层对用户随机分组：流量经过每一层时都会被打散重新分配，下一层的每一组的流量都随机来源于上一层各组的流量\n实现同一个用户出现在不同层的不同组中，流量重复利用\n\n分流分层模型：在此模型中增加组、层，并且可以相互嵌套。要求与实际的业务相匹配，拆分过多的结构可能会把简单的业务复杂化，拆分过少的结构又可能不满足实际业务。\n\n\n\n  上图就是分流分层模型的一个简单的图示。我们有：域1+域2=100%流量，B1层=B2层=B3层=域2流量，(B1-1)+(B1-2)+(B1-3)=B1层流量\n\n规则：\n\n域1和域2拆分流量，即域1域2互斥\n流量流过域2中的B1层、B2层、B3层时，B1层、B2层、B3层的流量都与域2的流量相等，此时B1层、B2层、B3层的流量是正交的\n流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2,B1-3，此时B1-1，B1-2,B1-3又是互斥的\n\n使用场景：\n\n例1：B1层、B2层、B3层可能分别为：UI层、搜索结果层、广告结果层，这基层基本上没有业务关联，即使共用相同的流量（流量正交）也不会对实际的业务造成结果。\n但是如果不同层之间所进行的实验相互关联，如B1层是修改的一个页面的按钮文字颜色，B2层时修改的按钮的颜色，当按钮文字颜色和文字颜色一样时，该按钮以及不可用了。因此建议同一类型的实验在同一层内进行，并且需要考虑到不同实验互相的依赖。\n例2：域1的此种分流意义在于：如果我们希望其他任何实验都不能对我们的实验造成干扰，保证最后实验的可信度。\n\nB端实验\n\n内容池：\n\n业务策略：低质过滤、热点运营、内容引入、内容使用天数\n模型更新：tag更新、清晰度调整、封面图调整、评分体系更新\n\n内容创作者：\n\n业务策略：账号过滤、账号提权、账号引入、分润策略\n模型更新：评级模型更新、黑产打击模型更新\n\n\nwhat——选物料\n\n  明确改动点——话术模版/H5/图片素材，保证是单一因素\n\nwhere——选渠道\n\n  短信/外呼/邮件/站内私信\n\nwhen——选时机\n\n  立即出发/定时触达/例行触达/事件触发\n  注意：实验时长要与产品的“数据特征周期”一致\n  例如：直播类app产品，用户在周一到周五的活跃度较低，在周末活跃度高，以一个自然周为周期，不断循环。那么该产品的实验的时长应设置为一周。\n\nHow Large——决定样本量\n\n在前面有介绍过具体公式，这里简化为\\(N  \\approx \\frac{16 \\times \\sigma^2}{\\delta^2}\\)\n\n样本标准差\\(\\sigma\\)衡量了整体样本数据的波动性\n\n观测指标为绝对值类指标时：\\(\\sigma^2 = \\frac{\\sum_i^n(x_i-\\bar{x})^2}{n-1}\\)\n观测指标为比率类指标时：\\(\\sigma^2 = p_A(1-p_A)+p_B(1-p_B)\\)，\\(p_A,p_B\\)为观测数据，比如希望点击率从20%提升到25%，那么\\(p_A=0.2,p_B=0.25,\\delta = 5%\\)\n\n组间预期差值\\(\\delta\\)代表预期实验组和对照组两组数据的差\n这里我们取\\(\\alpha = 0.05,\\beta=0.2\\)，这里体现了AB实验的保守理念：低的\\(\\alpha\\)，尽量避免在\\(H_0\\)为真的时候拒绝它，；高的\\(\\beta\\)，可以适当的接受假的\\(H_0\\)，也就是说改进实际游泳但是不采取；总结下来就是宁肯砍掉多个号的产品，也不应该让任何不好的产品上线。\n\n\n\n\n\n\nNote\n\n\n\n为什么我们需要计算最小样本量？\n理论上样本量肯定是越大越好。实际上，样本量是越小越好，因为\n\n流量有限：小公司就这么点流量，还要精打细算做各种测试，开发各种产品。在保证样本分组不重叠的基础上，产品开发速度会大大降低。\n试错成本大：如果拿50%的用户做实验，一周以后发现总收入下降了20%，这样一周时间的实验给公司造成了10%的损失，这样损失未免有点大。\n\n所以也可以应用一个流量大小Trick——RAMP-UP PLAN or 灰度测试：初始阶段,先分配较少的流量（如1%）进入实验，初始实验如果一切正常, 进一步加大流量，初始实验如果出现异常, 随时可以终止实验\n\n\n\n理论基础——CLT\n\n当样本量足够大的时候，样本均值\\(\\bar{x}\\)的分布近似服从正态分布。\n当\\(H_0\\)为真的时候 ，实验组的样本均值\\(\\bar{x}\\)服从均值为\\(\\mu_t = \\mu_c\\)，方差为\\(\\frac{\\sigma^2}{n}\\)的正态分布。\n\n标准化后的\\(Z\\)统计量：\\(Z=\\frac{\\bar{x}-(\\mu_c-\\mu_t)}{\\sqrt{2\\sigma^2/n}}\\)\n第二类错误是指在H0为假的时候，我们错误地接受了H0，也就是说Z统计量落在了接受域内。\n\n\n\\[\\beta = P(|\\frac{\\bar{x}}{\\sqrt{2\\sigma^2/n}}| \\le Z_{\\alpha/2}) = P(-Z_{\\alpha/2} \\le \\frac{\\bar{x} - (\\mu_c - \\mu_t)}{\\sqrt{2\\sigma^2/n}} \\le Z_{\\alpha/2})\\]\n  由于中间部分服从标准正态分布，所以这个概率可以用正态分布的累计函数\\(\\Phi\\)来表示：\n\\[\\beta= \\Phi(Z_{\\alpha/2} - \\frac{\\mu_c - \\mu_t}{\\sqrt{2\\sigma^2/n}}) - \\Phi(-Z_{\\alpha/2} - \\frac{\\mu_c - \\mu_t}{\\sqrt{2\\sigma^2/n}})\\]   不失一般性，我们假设\\(\\mu_c&gt;\\mu_t\\)是一个比较大的整数，所以其中第二项\\(\\Phi(-Z_{\\alpha/2} - \\frac{\\mu_c - \\mu_t}{\\sqrt{2\\sigma^2/n}})\\)的值会非常小，接近与0，因此可以忽略。与此同时，我们知道\\(\\beta = \\Phi(-Z_{\\beta})\\)，最终可以得到\\[n \\approx \\frac{2(Z_{\\alpha/2} + Z_\\beta)^2 \\sigma^2}{(\\mu_c - \\mu_t)^2}\\]。其中\\(\\delta = |\\mu_t-\\mu_c|\\)是我们希望检测到的最小可检测效应MDE。\\(\\sigma^2\\)是指标的方差，通常需要预估或者根据历史数据计算。\n  以上公式是计算出单个实验组所需的样本量，若有多个实验组，乘以实验组的个数就可以得到最终的样本量；样本量也可以是一段时间里累计的样本量，比如需要10000个样本，每天1000个，累计10天也是可以的。\n\n举例：\n\n对于绝对值指标：\n\n某商品详情页平均停留时长的标准差是20s，优化了商品详情页面后，预估至少有5s的提升，AB测试每个组需要的最少样本量：\\(\\sigma = 20,\\delta=5\\)，每个组所需要的最少的样本量就是16*202/52=256\n\n比率类指标：\n\n某商品详情页点击率20%，优化后预期点击率提升到25%，每个组需要的最少样本量：16(0.20.8+0.25*0.75)/(0.25-0.2)**2\n\n\n在线计算工具：Evans awesome AB Tools\n代码（基于\\(delta\\) \\(method\\)）:\\(\\sqrt{n}(g(Y_n) - g(\\theta)) \\xrightarrow{d} N(0, \\sigma^2 g'(\\theta)^2)\\)\n\n\nimport numpy as np\nimport math\nfrom sklearn.linear_model import MultiTaskLasso, Lasso\nimport pandas as pd\nimport scipy.stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n用卡方检验检验分流的均匀性\n\n\nx 和 y：通常代表实验组和对照组的用户总数（或流量总数）。代码中的 31188, 31188 表示两组的流量是相等的。\nx_target 和 y_target：通常代表实验组和对照组中某个特定事件的发生次数，例如转化、点击等。代码中的 3461, 3423 是两组的转化次数。\n如果p-value非常小（比如小于0.05），说明两组的流量分布存在显著差异，可能分流有问题，实验结果不可信。\n\n\nfrom scipy.stats import chi2_contingency\ndef chi_test(x,y,x_target,y_target):\n    kf_data = np.array([[x,x_target], [y,y_target]])\n    kf = chi2_contingency(kf_data)\n    print('chi-sq=%.4f, p-value=%.4f, df=%i expected_frep=%s'%kf)\n\nchi_test(31188,31188,3461,3423)\n\nchi-sq=0.1780, p-value=0.6731, df=1 expected_frep=[[31205.1115218  3443.8884782]\n [31170.8884782  3440.1115218]]\n\n\n\n德尔塔方法计算方差\n\n\n计算两个随机变量之比的方差。在ABTest中，CTR = 点击数/曝光数，CVR = 转化数/点击数，这两个指标本质上都是两个随机变量的商。\n问题背景：传统的二项分布方差公式适用于伯努利试验（例如每个用户点击或者不点击）。但是对于比率指标，分母本身也是一个随机变量。这时使用简单的二项分布公式来估算方差就不正确了。\n推导：假设我们需要计算\\(R = Y/X\\)的方差。通过一阶泰勒展开近似，得到\\(Var(\\hat{R}) = Var\\left(\\frac{\\bar{Y}}{\\bar{X}}\\right) \\approx \\left(\\frac{\\partial g}{\\partial x}\\right)^2 Var(\\bar{X}) + \\left(\\frac{\\partial g}{\\partial y}\\right)^2 Var(\\bar{Y}) + 2\\left(\\frac{\\partial g}{\\partial x}\\right)\\left(\\frac{\\partial g}{\\partial y}\\right)Cov(\\bar{X}, \\bar{Y})\\)，其中\\(g(x,y) = \\frac{y}{x},  \\frac{\\partial g}{\\partial x} = -\\frac{y}{x^2}, \\frac{\\partial g}{\\partial y} = \\frac{1}{x}\\)，代入得到\\(\\Rightarrow Var(\\hat{R}) \\approx \\frac{E[Y]^2}{E[X]^4} Var(\\bar{X}) + \\frac{1}{E[X]^2} Var(\\bar{Y}) - \\frac{2E[Y]}{E[X]^3} Cov(\\bar{X}, \\bar{Y})\\)\n\n\ndef var_dtm(y_mean, x_mean, var_y, var_x, xy_mean):\n    #计算协方差\n    def cova(x_mean,y_mean,xy_mean):\n        return xy_mean-x_mean*y_mean\n    covar = cova(x_mean,y_mean,xy_mean)\n    \n    #商的variance\n    var_ratio = var_y/x_mean**2 + var_x*y_mean**2/x_mean**4 - 2*covar*y_mean/x_mean**3\n    return var_ratio\n  \n  \n#发布器头图的 曝光数 &gt; 发布数 为例\nvar = var_dtm(y_mean = 0.035214194, x_mean = 2.794877088302219\n                ,var_y = 0.073726526, var_x = 185.240175\n                    , xy_mean = 0.410843231521)\n\n\n#实际的方差 有可能比二项分布折算方差会大很多\nprint('二项方差：',round(0.012599/(1-0.012599),4))\n\n二项方差： 0.0128\n\nprint('实际方差：',round(var,4))\n\n实际方差： 0.0122\n\n\n\n估算样本量\n\n\n'''\nmean:对照组指标的均值（如基准转化率）\nvar：指标的方差，代码在调用时会分别使用“二项分布方差”和“德尔塔方法方差”。\nlift_rate：预期的最小可检测效应\\delta\n'''\n\n'\\nmean:对照组指标的均值（如基准转化率）\\nvar：指标的方差，代码在调用时会分别使用“二项分布方差”和“德尔塔方法方差”。\\nlift_rate：预期的最小可检测效应\\\\delta\\n'\n\ndef sample_size(mean = 0.01259955,var = 0.0122,lift_rate = 0.025,alpha = 0.05,beta = 0.2):\n    import math\n    \n    lift = lift_rate * mean\n    num = var*(scipy.stats.norm.ppf(1-alpha)+scipy.stats.norm.ppf(1-beta))**2/(lift**2)\n    return math.ceil(num)\n\nprint('采用二项方差的样本量估计：', sample_size(var = 0.0128))\n\n采用二项方差的样本量估计： 797606\n\nprint('采用deltaMethod的样本量估计：',sample_size())\n\n采用deltaMethod的样本量估计： 760218\n\n\n\n\n4.3.4 4.实施与随机化，数据收集与监控\n\n开发并部署实验变体（B）\n\n创建变体：对网站原有版本的元素进行所需要更改。可能是更改颜色，交换页面上元素是顺序，隐藏导航元素或完全自定义的内容。\n\n构建可靠的随机化引擎，确保分配是真正的随机且不可预测的。常用方法：用户ID哈希取模、伪随机数生成器（需要确保seed独立）。\n记录分配日志（用户ID，时间戳、分配组、实验ID）（埋点）\n\n这里要注意辛普森悖论！要严格执行之前设计的分流分层方案让样本均匀随机。\n\n收集核心指标、护栏指标、探索性指标的数据（埋点采集数据）\n实时/准实时监控：\n\n样本量积累情况\n\n比如实验组和对照组的分流的流量是否均匀\n\n核心指标的点估计和置信区间变化\n护栏指标是否有异常波动（设置警报阈值）\n检查AA测试是否通过\n观察对于用户的行为埋点是否埋的正确\n\n\n\n\n4.3.5 5.数据分析\n\n数据准备：清洗数据，处理异常值，确认分析窗口（如实验开始后稳定期的数据）。\nAA测试/平衡检验：在分析AB结果之前，先检查实验组（A）和对照组（A）在已知不受实验影响的指标上（如实验前历史数据、用户属性、分流前行为）是否存在显著差异。若显著，表明随机化可能失败或者数据有问题，需要排查。\n效应估计：计算核心指标的组间差异\\(\\bar{y}_B-\\bar{y}_A\\)或者\\(\\hat{p}_B-\\hat{p}_A\\)\n统计显著性差异：使用合适的检验方法（t检验、Z检验、回归）计算P值\n\n\n\n\n\n\n\n\n\n\n指标类型\n检验方法\n公式\n适用场景\n\n\n\n\n连续型指标(人均时长、客单价)\n双样本t检验\n\\(t = \\frac{\\bar{Y}_A - \\bar{Y}_B}{\\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}}}\\)\\(df \\approx \\frac{(\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B})^2}{\\frac{(\\frac{s_A^2}{n_A})^2}{n_A-1} + \\frac{(\\frac{s_B^2}{n_B})^2}{n_B-1}}\\)\n收入、时长等平滑分布数据\n\n\n比例型指标(转化率、点击率)\n双样本Z检验\n\\(Z = \\frac{\\hat{p}_A - \\hat{p}_B}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_A} + \\frac{1}{n_B})}}\\)\\(\\hat{p} = \\frac{X_A + X_B}{n_A + n_B}\\)\n转化率、留存率等二分类数据\n\n\n计数型指标(人均点击次数)\n负二项回归(处理过离散)\n\\(\\log(\\mu_i) = \\beta_0 + \\beta_1 \\cdot \\text{Treatment}_i\\)\\(\\text{Var}(Y_i) = \\mu_i + \\alpha\\mu_i^2\\)\n用户行为次数（方差&gt;均值）\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQ：为什么转化率、点击率是二分类的数据？\nA：然我们常把转化率、点击率表述为百分比（如5.2%），但它们的底层数据本质是二分类数据（Binary Data）。原因在于构成这些指标的每一个最小观察单元只有两种互斥状态：\n\n点击率CTR点击次数/曝光次数：点击记录为1，不点击记录为0\n转化率CVR注册次数/进入落地页人数：注册记录为1，不点击记录为0\n二分类数据违背连续型检验的核心假设：\n\n\n\n假设\n连续型变量\n二分类数据\n\n\n\n\n数据分布\n近似正态分布\nBournulli分布（0-1分布）\n\n\n方差稳定性\n方差与均值无关\n方差依赖均值$p(1-p)$\n\n\n数值范围\n无边界限制\n数值被压缩在[0,1]\n\n\n\n案例：广告点击率AB测试 (A组 vs B组)\n\nA组：曝光 10,000 次 → 点击 600 次 → \\(\\hat{p}_A = 0.06\\)\nB组：曝光 10,000 次 → 点击 750 次 → \\(\\hat{p}_B = 0.075\\)\n若错误使用t检验：\n\n计算两组的点击率（0.06vs0.075）的t统计量，得出p&lt;0.05\n问题：忽略数据的本质是离散二分类，且方差p(1-p)在p=0.5时最大，导致检验失真\n\n正确使用Z检验：\n\n\\(Z = \\frac{\\hat{p}_B - \\hat{p}_A}{\\sqrt{\\hat{p}(1-\\hat{p}) \\left( \\frac{1}{n_A} + \\frac{1}{n_B} \\right)}}, \\quad \\hat{p} = \\frac{600+750}{10000+10000} = 0.0675\\)\n得到Z=5.0,p&lt;0.000，结论可靠\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQ：什么时候可以近似使用t检验？\nA：当同时满足以下两个条件时，二分类数据近似生态分布，可以谨慎使用t检验\n\n样本量足够大：\\(n \\cdot p &gt;5\\)且\\(c\\cdot(1-p)&gt;5\\)\n比例值远离边界：\\(0.2&lt;p&lt;0.8\\)，避免p接近0或1导致分布高度偏态\n\n当然，互联网场景中，转化率等常不满足，严格使用比例检验或逻辑回归。\n\n\n\nCI构建：计算效应量的CI\n多重检验校正：如果同时考虑多个核心指标或者同一个指标的多个变体（A/B/n测试），需要进行校正，以控制整体错误发现率（FDR）或族系错误率（FWER）。容易忽视但是很重要！\n效应量解读：结合实际业务解读统计学差异是否显著。一个统计学上显著但是效应量微小的结果可能没有实际意义。\n\n\n\n4.3.6 6.决策\n\n显著且正向：发布B方案\n显著但负向：放弃B，分析原因\n不显著：\n\n检查功效：样本量是否足够？效应量是否小于MDE？\n检查实验设计：随机化是否有效？指标定义是否合理？触发逻辑是否正确？\n结论：在当前条件下，未检测到B方案与A方案有统计显著差异。这不等于证明两者效果相同（可能是II类错误）。\n\n考虑结果在实际流量下的稳健性（如网络效应、长期效应）\n\n\n\n\n\n\n\nNote\n\n\n\nQ：如果你发现你在AB测试当中所选取的指标在统计上来说都是不显著的，你该怎么去判断这个实验的收益？\nA：\n\n在当前条件下，未检测到B方案与A方案有统计显著差异。这不等于证明两者效果相同（可能是II类错误）\n但进一步，我们可以将这个指标去拆分成每一天去观察，如果指标的变化曲线每一天实验组都高于对照组，即使他在统计上来说是不显著的，我们也认为在这一个观测周期内，实验组的关键指标表现是优于对照组，并得出优化上线的结论。\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQ：如果你在AB测试中发现实验组核心指标明显优于对照组，那这个优化就一定能够上线吗？\nA：\n\n不一定。举个例子，比如说有的时候我们想要提升产品的视觉展现效果。但是这种优化可能是以用户等待内容展现的时间作为代价来进行提升的。所以一个方面的优化可能会导致另一个方面的劣化。在做这个优化的时候，可能会对其他部门产生一些负向的影响，进而导致公司收入的下降。\n所以，我们在进行AB测试的时候，必须要综合评估所有方面的一些指标变动，同时对于收益和损失来做一个评估，才能确认这个优化可以最终上线。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ABTest</span>"
    ]
  },
  {
    "objectID": "02ABTest.html#挑战与陷阱",
    "href": "02ABTest.html#挑战与陷阱",
    "title": "4  ABTest",
    "section": "4.4 挑战与陷阱",
    "text": "4.4 挑战与陷阱\n  其实常见的错误总得来说就是两类，一类是弃真，一类是存伪。\n  弃真是指实验组和对照组没有显著差异，但是我们接受了新方案。减少这种错误的方法就是提高显著性水平\\(\\alpha\\)，比如p小于0.05才算显著，而不是选用0.1   存伪是指实验组和对照组有显著差异，但是我们没有接受新方案。这是第II类错误。\n\n4.4.1 新奇效应（Novelty Effect）/首因效应（Primacy Effect）\n  用户对新方案B的暂时性好奇或抵触导致行为短期偏离长期趋势。\n量化公式\n\n首因效应强度 = \\(\\frac{\\text{老用户实验组留存率} - \\text{老用户对照组留存率}}{\\text{新用户实验组留存率} - \\text{新用户对照组留存率}}\\) （比值&gt;1.3表示显著存在）\n新奇效应衰减率 = \\(1 - \\frac{\\text{实验组第7日DAU}}{\\text{实验组第2日DAU}}\\) （衰减率&gt;40%需警惕）\n\n解决方案：延长实验时间观察指标是否稳定；考虑仅对新用户实验\n\n实验设计阶段\n\n将用户分为 认知锚点人群（老用户）和 无锚点人群（新用户）\n对新用户设置 学习期（前3天数据仅监控不分析）\n\n数据分析阶段\n\n\ndef adjust_novelty_effect(data):\n    # 剔除前3天的新奇效应数据\n    adjusted_data = data[data['day'] &gt; 3] \n    # 计算首因效应修正因子 (基于老用户衰减曲线)\n    primacy_factor = fit_decay_curve(old_user_data)\n    return adjusted_data * primacy_factor\n\n\n决策阶段：\n\n若首因效应主导，需教育用户（如添加新功能引导教程）\n若新奇效应主导，关注长期留存曲线（看第30天留存率）\n例如：“当实验组在第4周留存率比对照组高5%，即使首周数据差也值得发布”\n\n\n\n\n\n\n\nNote\n\n\n\nQ：对于一个新功能实施了ABtest，发现新功能效果 更好，但是一周之后效果迅速下降。\nA：新奇效应，效果消失后重复使用减少\n\n\n\n\n\n4.4.2 样本比例不平衡（Sample Ratio Mismatch - SRM）\n  实际分配的人数比例与设计比例（例如50:50）存在显著偏差。严重！\n可能的原因：\n\n随机化算法bug\n数据管道问题\n用户重复计数\n实验配置错误\n\n错误的例子：\n\n实验中，在不同渠道/应用市场中，发布不同版本的APP/页面，并把用户数据进行对比\n简单地从总体流量中抽取n%用于实验，不考虑流量分布，不做分流处理\n\n  不同应用市场渠道的用户常常带有自己的典型特征，用户分布具有明显区别。对总流量进行简单粗暴地抽样也有着同样的问题——分流到实验组和对照组的流量可能存在很大的分布差异。\n  AB测试要求我们尽可能地保持实验组和对照组的流量分布一致，与总流量也需分布一致，否则得出的实验数据不具有可信度。\n  必须解决SRM才能分析结果！\n\n\n4.4.3 辛普森悖论（Simpson’s Paradox）\n  在子群体中观察到的趋势与合并数据中的趋势相反。\n\n\n4.4.4 相关实验的相互影响\n  前面有讲到，相关性实验放到同一层，不相关的实验可以放在不同层。比如按钮红色or蓝色VS按钮圆形or方形是相关的实验，用户将收到“按钮颜色Red”以及“按钮形状Round”两个策略的影响。\n\n\n\n\n\ngraph TD\n    U[用户] --&gt;|同时经历| E1[颜色实验]\n    U --&gt;|同时经历| E2[形状实验]\n    E1 --&gt;|红色/蓝色| D[点击行为]\n    E2 --&gt;|圆形/方形| D\n    D --&gt;|混杂结果| R[无法区分影响因素]\n\n\n\n\n\n\n  这样我们就无法判断究竟是哪个策略影响了该用户的行为。换句话说，由于两个实验存在关联，用户重复被实验命中，实验结果实际收到了多个策略的影响。这种情况下，两个实验的结果便不再可信了。\n\n传统正交分层（适合不相关实验）\n\n\n\n\n用户ID\n层1: 按钮颜色\n层2: 推荐算法\n\n\n\n\n1001\n蓝色\n算法A\n\n\n1002\n红色\n算法B\n\n\n1003\n蓝色\n算法A\n\n\n\n\n因子设计（2×2实验，解决相关问题）\n\n\n\n\n用户ID\n颜色+形状组合\n效果评估\n\n\n\n\n1001\n蓝色 + 方形\n转化率X%\n\n\n1002\n蓝色 + 圆形\n转化率Y%\n\n\n1003\n红色 + 方形\n转化率Z%\n\n\n1004\n红色 + 圆形\n转化率W%\n\n\n\n\n数据分析结果：\n\n\n\n\n组合方案\n用户数\n转化率\n平均订单额\n\n\n\n\n蓝色方形\n10000\n5.2%\n$128\n\n\n蓝色圆形\n10000\n6.1%\n$135\n\n\n红色方形\n10000\n5.8%\n$132\n\n\n红色圆形\n10000\n7.5%\n$145\n\n\n\n\n效应计算\n\n\nimport numpy as np\n\n# 定义各组转化率\nblue_square = 0.052\nblue_circle = 0.061\nred_square = 0.058\nred_circle = 0.075\n\n# 计算主效应和交互效应\ncolor_effect = ((red_square + red_circle) - (blue_square + blue_circle)) / 2\nshape_effect = ((blue_circle + red_circle) - (blue_square + red_square)) / 2\ninteraction = ((red_circle - red_square) - (blue_circle - blue_square)) / 2\n\nprint(f\"颜色主效应: {color_effect:.4f}\")    # 0.0100\n\n颜色主效应: 0.0100\n\nprint(f\"形状主效应: {shape_effect:.4f}\")    # 0.0130\n\n形状主效应: 0.0130\n\nprint(f\"交互效应: {interaction:.4f}\")       # 0.0040\n\n交互效应: 0.0040\n\n\n\n适用场景\n\n\n\n\n场景类型\n案例\n推荐设计\n\n\n\n\nUI元素交互\n按钮形状+颜色+文案\n2*2*2因子设计\n\n\n定价策略组合\n基础价+折扣+运费策略\n三因子混合设计\n\n\n产品功能叠加\n搜索+筛选+排序功能优化\n分阶段因子设计\n\n\n营销组合策略\n渠道+文案+优惠券类型\n正交分层+因子设计\n\n\n\n\n实施注意事项：\n\n四组实验需要四倍于单实验的样本量\n正交互效应是策略相互增强，负交互效应是策略相互抵消\n业务优先级：\n\n当交互效应&gt;主效应时，必须采用组合策略\n当主效应&gt;&gt;交互效应时，可以独立优化\n\n实验平台支持：\n\nclass FactorialExperiment:\n    def __init__(self, factors):\n        self.factors = factors  # 如 {'颜色': ['蓝','红'], '形状': ['方','圆']}\n        self.groups = self._generate_groups()\n\n    def _generate_groups(self):\n        \"\"\"生成所有因子组合\"\"\"\n        from itertools import product\n        return list(product(*self.factors.values()))\n\n    def assign_user(self, user_id):\n        \"\"\"分配用户到特定组合\"\"\"\n        hash_val = hash(user_id) % 100\n        group_size = 100 / len(self.groups)\n        group_idx = int(hash_val // group_size)\n        return self.groups[group_idx]\n\n\n黄金法则：当实验策略影响用户的同一决策时刻或同一认知维度时，必须使用因子设计而非正交分层。\n\n\n\n4.4.5 稀释效应（Dilution Effect）\n  指不符合实验触发条件的用户（如从未访问过实验页面的用户纳入分析），稀释了真实效应。\n解决方案：\n\n采用“仅曝光用户分析”或“触发用户分析”\n\n\n\n4.4.6 干扰（Interference）\n  一个用户的体验/行为收到其他用户所在组的影响（如社交功能）。违背了SUTVA（稳定单位处理值假设）。\n网络效应（Networking Effect）控制组的用户会被实验组的用户影响\n例如：\n\n我们对司机的激励策略，司机群里会讨论所以会感觉自己受到了不公平的待遇\n假设好友被分到了实验组，我被分到了对照组。曝光给好友的内容更加的有吸引力，他作出了点赞、评论等互动行为。而产品的社交属性，使我可以看到好友的互动行为，原本不会被曝光给我的内容，我通过好友的互动间接接收到了。也提高了我去互动的概率，提高了活跃程度。这样就发生了实验组想对照组溢出的问题，独立的假设受到了破坏。\n直播pk体验中，pk组的体验组连线对战组\n\n解决方案：用户聚类：按用户的关联度将用户聚成cu，保证簇内用户的关联强，而簇间的关联弱，那么簇与簇之间是近似独立的\n\n假如一个用户被划分到对照组中，那么大部分与他直接联系的用户也应该被划分到对照组中。\n\nTwo_sided markets实验组和对照组会竞争一样的资源\n\n当领券的用户需求增加，会获得更多的司机资源，从而让没领券的对照组可用的司机资源减少了！\n如果在一个地理区域中划分实验组和对照组，验证一个乘客端的优化。如果实验组的优化带来了需求的提升，那就会有更多的司机接到了来自实验组的订单。短时间内司机的数量固定，分配给实验组的司机多了，自然对照组的司机就少了。导致实验组结果高估，且破坏了独立假设。\n解决方案：系统控制干预，\n\n地理分离：从地理上区隔用户，这种情况适合打车平台这种能从地理上区隔的，比如北京作为实验组，上海作为对照组，需要两个城市的样本量相近。\n时间分离：只有在effect短的时候（比如打车）才有用，但长时间（比如是否会推荐给其他用户）就没用\n\n\n解决方案：核心是系统控制干预，降低对照组用户（没上策略的用户）接触到待评估功能的几率\n\n以更大粒度（群组/网络）随机化\n使用聚类标准误\n设计特殊实验\n\n时间片轮转实验：是一种处理个体之间相互干扰的实验方法，在一定的实验对象上 进行实验组策略和对照组策略上的反复切换。比如快手直播PK：让用户无法知晓下一个时间是否是实验组\n\n\n\n\n4.4.7 统计显著\\(\\neq\\)实际显著\n\n\n\n\n\n\nNote\n\n\n\nQ：如果发现AB测试的结果在统计上显著，但是在实际中不显著，这是为什么？\nA：   统计学上的显著并不意味着实际效果的显著，假说检验只是告诉我们数据差异由随机产生的概率多大，而实际显著是一个业务对改进商业价值的业务判断。\n  比如，我们做了一个改动让APP的启动时间的优化了0.001秒，这个数字可能在统计学上对应的P值很小——统计学显著，但是在实际中用户0.01秒的差异是感知不出来的。那么这样一个显著的统计差别，其实是没有商业意义的。\n  造成这个结果可能的原因是我们在AB测试当中所选取的样本量过大（比如样本量分母的Minimum detectable effect太小了），导致样本和总体数据量差异很小，这样的话即使我们发现一个细微的差别，它在统计上来说是显著的，但对实际应用来说是不显著的。\n  解决方法就是我们要设定一个合理的Minimum detectable effect，并根据它计算最小样本量。\n\n\n\n\n4.4.8 多重检验问题（Multiple Testing Problem）\n  同时检验多个假设或多次查看数据（peeking）会大大增加整体I类错误。\n\n\n\n\n\ngraph TD\n    A[开始实验] --&gt; B[第3天查看结果]\n    B --&gt; C{结果显著？}\n    C --&gt;|是| D[提前终止]\n    C --&gt;|否| E[继续实验]\n    D --&gt; F[虚假结论]\n    E --&gt; B\n\n\n\n\n\n\n\n  例如，有三个组，有一个组p-value&lt;0.05，也不能执行，因为此时：\n\nPr(no false positive) = (1 - 0.05) ^3 = 0.857\nPr(at least 1 false positive) = 1 - 0.857 = 0.143\nType I error rate over 14%\n\n  例如\n解决方案：\n\n预先实验周期计算\n\n完整周期公式：\\(T = max(7, \\frac{n}{N_{\\text{daily}}} ) \\times \\text{季节因子}\\)，\\(n\\) = 基于MDE计算的样本量，\\(N_{\\tet{daily}}\\) = 日均可用流量，季节因子 = 1.2（促销季）或 0.8（淡季）\n\n使用序贯检验或贝叶斯方法处理peeking\n\n\n# 序贯检验\n# O'Brien-Fleming边界示例\ndef obrien_fleming_bound(alpha, t, T):\n    \"\"\" t:当前信息分数, T:计划总信息量 \"\"\"\n    z = stats.norm.ppf(1 - alpha/2)\n    return z * np.sqrt(T / t)\n    \n# 第50%进度时边界：z*√2 ≈ 1.414z (比固定检验更严格)\n\n# 贝叶斯方法\ndef should_stop(prior, data_A, data_B):\n    posterior = update_posterior(prior, data_A, data_B)\n    prob_better = (posterior['B'] &gt; posterior['A']).mean()\n    return prob_better &gt; 0.95 or prob_better &lt; 0.05\n\n\n对结果进行多重检验校正\n\n真实案例：电商大促按钮测试\n\n实验设定：\n\n目标：测试购物车按钮颜色（红VS蓝）\n预定周期：14天（覆盖两个完整周末）\n每日流量：100,000用户\n\nData Peeking导致的错误决策：\n\n\n\n\n实验日\n操作\n观测结果\n实际最终结果\n\n\n\n\n第3天\n查看数据并终止\n“红色胜出12%”\n虚假结论\n\n\n第7天\n查看数据并继续\n“无差异”\n-\n\n\n第14天\n完整数据分析\n“蓝色胜出2%”\n真实结论\n\n\n\n\n损失评估：\\(\\text{机会成本} = 7\\text{天} \\times 100\\text{K用户/天} \\times 2\\% \\times \\text{客单价} = \\$140,000\\)\n\n\n\n4.4.9 长期效应（Long-term Effects）\n  AB测试通常运行几天到几周，可能无法捕捉方案的长期影响（如用户疲劳、生态变化）。\n解决方案：\n\n结合长期跟踪研究\n使用“保留组”进行长期观察\n\n\n\n4.4.10 方差估计问题\n  这一点在前面也有提到。用户级指标常常存在用户内行为相关性（非独立），导致传统方差估计低估。\n解决方法：使用Delta方法、自助法(Bootstrap)、或基于用户聚类的标准误（Cluster-Robust Standard Errors）。对用户级分流尤其关键！\n\n\n4.4.11 外部环境带来偶然因素\n下雨天打车、大促时电商\n\n\n4.4.12 单侧检验\n  当显著性水平一定时，如要在多个选件中确定入选者，那么单侧检验所需观察到的选件之间的转化率差异更小。这似乎很有吸引力，因为与使用双侧检验相比，单侧检验可以更早地确定入选者。但单侧检验是有代价的！\n  例如，在一个单侧检验中，测试B是否比A好必须在开始测试之前，决定是测试 B 优于 A 还是 A 优于B。但是，如果是先查看了 A/B 测试的结果并看到 B 优于 A，然后决定进行一个单侧检验来看这种差异是否具有统计意义，那么就违反了统计测试背后的假设。违反测试的假设意味着您的置信区间不可靠，并且测试的误报率比预期的要高。\n  您可以将单侧检验看做是一种已经由裁判做出决定、只是对该选件进行试验的测试。在单侧检验中，您已经确定了入选选件，而且只是想证明这一点，而不是向每个体验提供平等的机会来证明自己可以是入选者。单侧检验只应在这种极少发生的情况下使用：您只关注某个策略是否优于其他策略，而不是其他策略优于某个策略。\n  避免出现单侧检验问题，我们通常使用始终运用双侧检验的 A/B 测试解决方案！\n\n\n4.4.13 贝叶斯AB测试（Bayesian AB Testing）\n待补充\n\n\n4.4.14 序贯检验（Sequential Testing）\n\n允许在实验运行过程 中多次查看数据并可能提前停止实验（当结果足够显著或明显无效时）\n能控制整体I类错误率（如使用序贯概率比检验——SPRT，Alpha Spending Functions）\n提高实验效率（尤其当效应很大或很小），减少资源浪费\n\n\n\n4.4.15 A/B/n Tesing & 多臂老虎机（Multi-armed Bandit - MAB）\n\nA/B/n：同时测试多个变体（A/B/C/D…）。需要多重检验校正\nMAB：一种在线学习算法，在探索（收集信息）和利用（选择当前最优）之间动态平衡流量分配。适用于需要持续优化且快速反馈的场景（如广告竞价）。牺牲严格的因果推断换取更快的收益提升。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ABTest</span>"
    ]
  },
  {
    "objectID": "02ABTest.html#aa实验",
    "href": "02ABTest.html#aa实验",
    "title": "4  ABTest",
    "section": "4.5 AA实验",
    "text": "4.5 AA实验",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ABTest</span>"
    ]
  }
]